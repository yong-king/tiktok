# çŸ­è§†é¢‘é¡¹ç›®

# ç¯å¢ƒæ­å»º

## mysqlï¼š

```bash
docker pull mysql:8.0.36

docker run --name mysql -v /d/my_program/docker/mysql/data:/var/lib/mysql -v /d/my_program/docker/mysql/conf:/etc/mysql/conf.d -v /d/my_program/docker/mysql/log:/var/log/mysql -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql:8.0.36

```

userï¼š

```sql
CREATE DATABASE tiktok DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;

CREATE TABLE `users` (
                         `id` BIGINT UNSIGNED NOT NULL PRIMARY KEY COMMENT 'ç”¨æˆ·IDï¼Œé›ªèŠ±ç®—æ³•ç”Ÿæˆ',
                         `username` VARCHAR(64) NOT NULL UNIQUE COMMENT 'ç”¨æˆ·åï¼Œå”¯ä¸€',
                         `password_hash` VARCHAR(255) NOT NULL COMMENT 'åŠ å¯†åçš„å¯†ç ',
                         `avatar` VARCHAR(255) DEFAULT NULL COMMENT 'ç”¨æˆ·å¤´åƒURL',
                         `background_image` VARCHAR(255) DEFAULT NULL COMMENT 'ä¸ªäººé¡µèƒŒæ™¯å›¾',
                         `signature` VARCHAR(255) DEFAULT NULL COMMENT 'ä¸ªæ€§ç­¾å',
                         `follow_count` INT UNSIGNED NOT NULL DEFAULT 0 COMMENT 'å…³æ³¨æ•°',
                         `follower_count` INT UNSIGNED NOT NULL DEFAULT 0 COMMENT 'ç²‰ä¸æ•°',
                         `work_count` INT UNSIGNED NOT NULL DEFAULT 0 COMMENT 'ä½œå“æ•°',
                         `favorite_count` INT UNSIGNED NOT NULL DEFAULT 0 COMMENT 'å–œæ¬¢æ•°',
                         `total_favorited` INT UNSIGNED NOT NULL DEFAULT 0 COMMENT 'è·èµæ€»æ•°',
                         `tags` JSON DEFAULT NULL COMMENT 'æ ‡ç­¾ï¼ˆAIç”»åƒä½¿ç”¨ï¼‰',
                         `status` TINYINT NOT NULL DEFAULT 1 COMMENT 'è´¦å·çŠ¶æ€ï¼š1æ­£å¸¸ï¼Œ0å°ç¦',
                         `extra` JSON DEFAULT NULL COMMENT 'æ‰©å±•å­—æ®µï¼Œé¢„ç•™ç»™æœªæ¥åŠŸèƒ½',
                         `reserved1` VARCHAR(255) DEFAULT NULL COMMENT 'é¢„ç•™å­—æ®µ1',
                         `reserved2` VARCHAR(255) DEFAULT NULL COMMENT 'é¢„ç•™å­—æ®µ2',
                         `created_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
                         `updated_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æ›´æ–°æ—¶é—´',
                         `deleted_at` TIMESTAMP NULL DEFAULT NULL COMMENT 'è½¯åˆ é™¤æ—¶é—´'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='ç”¨æˆ·åŸºç¡€è¡¨';

```

### gorm

```protobuf
go get -u gorm.io/gorm
go get -u gorm.io/driver/sqlite
```

## redisï¼š

```bash
docker pull redis:7.2.4
	
docker run --name redis -v /d/my_program/docker/redis:/data -p 6379:6379 -d redis:7.2.4
```

## kratos

å®‰è£…

```go
go install github.com/go-kratos/kratos/cmd/kratos/v2@latest
```

## protoc

```go
// ä¸‹è½½protoc 
https://github.com/protocolbuffers/protobuf/releases

// bin/protoc.exe
// å¤åˆ¶åˆ°gopath
// protoc.exe æ‰€åœ¨çš„ç›®å½•è·¯å¾„åŠ å…¥åˆ°ç¯å¢ƒå˜é‡ %PATH% ä¸­
// protoc --version
```

# uesr-service

```protobuf
syntax = "proto3";
option go_package = "user/api/user/v1;v1";
package user;

import "google/api/annotations.proto";

service UserService {
  rpc Register(RegisterRequest) returns (RegisterReply) {
    option (google.api.http) = {
      post: "/api/user/register"
      body: "*"
    };
  };
  rpc Login(LoginRequest) returns (LoginReply) {
    option (google.api.http) = {
      post: "/api/user/login"
      body: "*"
    };
  };
  rpc UserInfo(UserInfoRequest) returns (UserInfoReply) {
    option (google.api.http) = {
      get: "/api/user"
    };
  }
}

//  =========================ç”¨æˆ·æ³¨å†Œ============================

message RegisterRequest {
  string username = 1; // ç”¨æˆ·åï¼Œæœ€é•¿ä¸º32ä½
  string password = 2; // å¯†ç ï¼Œæœ€é•¿ä½32ä½
}

message RegisterReply {
  int32 status_code = 1;
  string status_msg = 2;
  int64 user_id = 3;
  string token = 4;
}

//  ==========================ç”¨æˆ·ç™»å½•============================
message LoginRequest {
  string username = 1;
  string password = 2;
}

message LoginReply {
  int32 status_code = 1;
  string status_msg = 2;
  int64 user_id = 3;
  string token = 4;
}

//  ===========================ç”¨æˆ·ä¿¡æ¯===========================
message UserInfoRequest {
  int64 user_id = 1;
  int64 current_user_id = 2; // å½“å‰ç™»å½•ç”¨æˆ·IDï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦å…³æ³¨ï¼‰
}

message UserInfoReply {
  int32 status_code = 1;
  string status_msg = 2;
  User user = 3;
}

message User {
  int64 id = 1; // ç”¨æˆ·id
  string name = 2;  // ç”¨æˆ·åç§°
  int64 follow_count = 3; // å…³æ³¨æ€»æ•°
  int64 follower_count = 4; // ç²‰ä¸æ€»æ•°
  bool is_follow = 5; // true-å·²å…³æ³¨ï¼Œfalse-æœªå…³æ³¨
  string avatar = 6;  // ç”¨æˆ·å¤´åƒ
  string background_image = 7;  // ç”¨æˆ·ä¸ªäººé¡µé¡¶éƒ¨å¤§å›¾
  string signature = 8; // ä¸ªäººç®€ä»‹
  int64 total_favorited = 9;  // è·èµæ•°é‡
  int64 work_count = 10;  // ä½œå“æ•°é‡
  int64 favorite_count = 11;  // ç‚¹èµæ•°é‡
}
```

```protobuf
// ç”Ÿæˆclient
kratos proto client api/user/v1/user.proto

// ç”Ÿæˆservice
kratos proto server api/user/v1/user.proto -t internal/service
```

## ç”¨æˆ·æ³¨å†Œ

```go
kratos new user-service
```

1. æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å­˜åœ¨
2. ç”¨æˆ·å¯†ç åŠ å¯†
3. é›ªèŠ±ç®—æ³•ç”Ÿæˆuser_idï¼Œjwtç”Ÿæˆtoken
4. æ³¨å†Œç”¨æˆ·
5. è¿”å›ç”¨æˆ·ä¿¡æ¯
6. æ·»åŠ é€»è¾‘
    1. ç”¨æˆ·æ ¡éªŒï¼Œå¯†ç ä¸ºç©ºä¹Ÿè¿”å›ï¼Œç›´æ¥æŠ¥é”™

## ç”¨æˆ·ç™»å½•

1. ç”¨æˆ·èº«ä»½æ ¡éªŒ
    1. æ ¹æ®idå’Œå¯†ç 
2. jwtç”Ÿæˆtokenï¼Œåˆ¤æ–­tokenæ˜¯å¦è¿‡æœŸ
    1. è¿‡æœŸåˆ·æ–°
3. è¿”å›å“åº”
4. æ‰©å±•
    1. é€€ç™»å½•  â€”â€”â†’ state 0,    ç™»å½• â€”â€”â†’ 1ï¼Œ ç”¨æˆ·å¼‚å¸¸çŠ¶æ€ â€”â€”â€”â€”> 3ï¼ˆå°å·ï¼‰
    2. åŒæ—¶åªèƒ½ç”±ä¸€ä¸ªåœ¨çº¿
    3. ç”¨æˆ·åæˆ–è€…å¯†ç ä¸ºç©ºç›´æ¥è¿”å›æŠ¥é”™ç™»å½•å¤±è´¥

## è·å–ç”¨æˆ·ä¿¡æ¯

1. å½“å‰ç”¨æˆ·ã€è¢«è·å–çš„ç”¨æˆ·çš„ä¿¡æ¯
2. æ ¹æ®ç”¨æˆ·idè·å–ç”¨æˆ·ä¿¡æ¯
3. æ‰©å±•
    1. å½“å‰ç”¨æˆ·ä¸è¢«æŸ¥è¯¢ç”¨æˆ·çš„å…³ç³»
    2. ç”¨æˆ·åæˆ–è€…å¯†ç ä¸ºç©ºç›´æ¥è¿”å›æŠ¥é”™ç™»å½•å¤±è´¥
        1. è¿™é‡Œå¯èƒ½éœ€è¦è°ƒæ•´ï¼Œæ¯”å¦‚åº”è¯¥åªæ˜¯è·å–ä¸ªäººçš„ä¿¡æ¯
            1. åˆ¤æ–­idæ˜¯å¦ä¸ºç©º
            2. è§£ætoken ä¸å½“å‰idæ˜¯å¦ç›¸åŒ
            3. æ ¹æ®idå»æŸ¥åº“

## ç”¨æˆ·ä¿¡æ¯çš„æ·»åŠ 

1. ç”¨æˆ·èƒŒæ™¯
2. ç”¨æˆ·å¤´åƒ
3. ç”¨æˆ·æ ‡ç­¾
4. ç”¨æˆ·æ ‡ç­¾
5. æ€§åˆ«
6. å¹´é¾„
7. åœ°åŸŸ

# video-service

### æ•°æ®åº“sql

```sql
CREATE TABLE `videos` (
  `id` BIGINT UNSIGNED NOT NULL PRIMARY KEY COMMENT 'è§†é¢‘IDï¼ˆé›ªèŠ±IDï¼‰',
  `user_id` BIGINT UNSIGNED NOT NULL COMMENT 'ä½œè€…ç”¨æˆ·ID',

  `play_url` TEXT NOT NULL COMMENT 'è§†é¢‘æ’­æ”¾åœ°å€',
  `cover_url` TEXT NOT NULL COMMENT 'è§†é¢‘å°é¢åœ°å€',
  `title` VARCHAR(255) NOT NULL COMMENT 'è§†é¢‘æ ‡é¢˜',
  `description` TEXT DEFAULT NULL COMMENT 'è§†é¢‘æè¿°',
  `duration` FLOAT DEFAULT 0 COMMENT 'è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰',
  `tags` TEXT DEFAULT NULL COMMENT 'è§†é¢‘æ ‡ç­¾',

  `favorite_cnt` INT DEFAULT 0 COMMENT 'ç‚¹èµæ•°',
  `comment_cnt` INT DEFAULT 0 COMMENT 'è¯„è®ºæ•°',
  `share_cnt` INT DEFAULT 0 COMMENT 'åˆ†äº«æ•°',
  `collect_cnt` INT DEFAULT 0 COMMENT 'æ”¶è—æ•°',

  `is_public` TINYINT(1) DEFAULT 1 COMMENT 'æ˜¯å¦å…¬å¼€ï¼ˆ0ç§å¯†ï¼Œ1å…¬å¼€ï¼‰',
  `audit_status` TINYINT DEFAULT 1 COMMENT 'å®¡æ ¸çŠ¶æ€ï¼ˆ0å®¡æ ¸ä¸­ï¼Œ1é€šè¿‡ï¼Œ2æ‹’ç»ï¼‰',
  `is_original` TINYINT(1) DEFAULT 1 COMMENT 'æ˜¯å¦åŸåˆ›ï¼ˆ1åŸåˆ›ï¼Œ0éåŸåˆ›ï¼‰',
  `source_url` TEXT DEFAULT NULL COMMENT 'åŸè§†é¢‘åœ°å€ï¼ˆéåŸåˆ›æ¥æºï¼‰',
  `transcode_status` TINYINT DEFAULT 1 COMMENT 'è½¬ç çŠ¶æ€ï¼ˆ0å¤±è´¥ï¼Œ1æˆåŠŸï¼Œ2è½¬ç ä¸­ï¼‰',

  `video_width` INT DEFAULT NULL COMMENT 'è§†é¢‘å®½åº¦ï¼ˆåƒç´ ï¼‰',
  `video_height` INT DEFAULT NULL COMMENT 'è§†é¢‘é«˜åº¦ï¼ˆåƒç´ ï¼‰',

  `biz_ext` JSON DEFAULT NULL COMMENT 'é€šç”¨æ‰©å±•å­—æ®µï¼ˆå­˜å‚¨åŠ¨æ€å±æ€§å¦‚æ¨èæ¥æºç­‰ï¼‰',
  `reserved_1` VARCHAR(255) DEFAULT NULL COMMENT 'é¢„ç•™å­—æ®µ1',
  `reserved_2` VARCHAR(255) DEFAULT NULL COMMENT 'é¢„ç•™å­—æ®µ2',

  `created_at` DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´ï¼ˆè§†é¢‘å‘å¸ƒæ—¶é—´ï¼‰',
  `update_time` DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æœ€åæ›´æ–°æ—¶é—´',
  `delete_at` DATETIME DEFAULT NULL COMMENT 'è½¯åˆ é™¤æ—¶é—´ï¼ˆéç©ºè¡¨ç¤ºè¢«åˆ é™¤ï¼‰',

  -- å•å­—æ®µç´¢å¼•
  KEY `idx_user_id` (`user_id`) COMMENT 'æ ¹æ®ç”¨æˆ·æŸ¥è§†é¢‘',
  KEY `idx_created_at` (`created_at`) COMMENT 'æŒ‰æ—¶é—´å€’åºå±•ç¤º',

  -- è”åˆç´¢å¼•
  KEY `idx_user_time` (`user_id`, `created_at` DESC) COMMENT 'ç”¨æˆ·è§†é¢‘åˆ—è¡¨åˆ†é¡µç”¨',
  KEY `idx_public_audit_time` (`is_public`, `audit_status`, `created_at` DESC) COMMENT 'è§†é¢‘æµæŒ‰æ—¶é—´ç­›é€‰å·²å®¡æ ¸çš„å…¬å¼€è§†é¢‘',

  -- æ’åºç±»ç´¢å¼•ï¼ˆçƒ­é—¨ã€æ¨èæ’åºä½¿ç”¨ï¼‰
  KEY `idx_favorite_cnt` (`favorite_cnt` DESC) COMMENT 'æ ¹æ®ç‚¹èµæ•°æ’åº',
  KEY `idx_comment_cnt` (`comment_cnt` DESC) COMMENT 'æ ¹æ®è¯„è®ºæ•°æ’åº',
  KEY `idx_share_cnt` (`share_cnt` DESC) COMMENT 'æ ¹æ®åˆ†äº«æ•°æ’åº',

  -- å®¡æ ¸åå°ç­›é€‰ç”¨
  KEY `idx_audit_status` (`audit_status`) COMMENT 'åå°å®¡æ ¸å¿«é€Ÿç­›é€‰'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='è§†é¢‘ä¿¡æ¯è¡¨';

```

## minio

```sql
mkdir -p ./minio/data

docker run -d --name minio \
   -p 9000:9000 \
   -p 9001:9001 \
   -e "MINIO_ROOT_USER=admin" \
   -e "MINIO_ROOT_PASSWORD=admin123" \
   -v ./minio/data:/data \
   quay.io/minio/minio:RELEASE.2023-12-20T01-00-02Z \
   server /data --console-address ":9001"

ç”¨æˆ·åï¼šadmin
å¯†ç ï¼šadmin123
```

### åˆ›å»ºæ¡¶ï¼švideo-flies,è®¾ç½®ä¸ºpublic

```sql
package pkg

import (
	"context"
	"fmt"
	"github.com/minio/minio-go/v7"
	"github.com/minio/minio-go/v7/pkg/credentials"
	"io"
	"video-service/internal/conf"
)

type MinioUploader struct {
	client     *minio.Client // MinIO å®¢æˆ·ç«¯
	bucketName string        // å­˜å‚¨æ¡¶åç§°
	endpoint   string        // MinIO è®¿é—®åœ°å€ï¼ˆå«ç«¯å£ï¼‰
}

// NewMinioUploader åˆå§‹åŒ– MinIO å®¢æˆ·ç«¯å¹¶ç¡®ä¿ bucket å­˜åœ¨
func NewMinioUploader(cfg *conf.Data_MinIO) (*MinioUploader, error) {
	// åˆ›å»º MinIO å®¢æˆ·ç«¯
	client, err := minio.New(cfg.Endpoint, &minio.Options{
		Creds:  credentials.NewStaticV4(cfg.AccessKeyID, cfg.SecretAccessKey, ""),
		Secure: cfg.UseSSL,
	})
	if err != nil {
		return nil, err
	}

	// æ£€æŸ¥ bucket æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
	ctx := context.Background()
	exists, err := client.BucketExists(ctx, cfg.BucketName)
	if err != nil {
		return nil, err
	}

	if !exists {
		err = client.MakeBucket(ctx, cfg.BucketName, minio.MakeBucketOptions{})
		if err != nil {
			return nil, err
		}
	}

	return &MinioUploader{
		client:     client,
		bucketName: cfg.BucketName,
		endpoint:   cfg.Endpoint,
	}, nil
}

// Upload ä¸Šä¼ æ–‡ä»¶åˆ° MinIO å¹¶è¿”å›å¤–éƒ¨å¯è®¿é—®çš„ URL
func (u *MinioUploader) Upload(ctx context.Context, objectName string, reader io.Reader, size int64, contentType string) (string, error) {
	// ä¸Šä¼ å¯¹è±¡
	_, err := u.client.PutObject(ctx, u.bucketName, objectName, reader, size, minio.PutObjectOptions{ContentType: contentType})
	if err != nil {
		return "", err
	}
	// æ„å»ºæ’­æ”¾åœ°å€ï¼ˆå‡è®¾ MinIO é…ç½®äº†å…¬å…±è®¿é—®ï¼‰
	playURL := fmt.Sprintf("http://%s/%s/%s", u.endpoint, u.bucketName, objectName)
	return playURL, nil
}

```

## ä¸Šä¼ è§†é¢‘

<aside>
ğŸ’¡

- æœåŠ¡ç«¯æ‹¿åˆ°è·¯å¾„æ²¡æ³•ä¿è¯å®ƒåœ¨ **æ­£ç¡®çš„æœºå™¨ã€æ­£ç¡®çš„æ–‡ä»¶ç³»ç»Ÿ** æœ‰æƒé™è¯»è¿™ä¸ªè·¯å¾„ï¼ˆå°¤å…¶æ˜¯å®¹å™¨åŒ–ã€K8s ä¸­æ¯ä¸ª Pod çš„æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿæ˜¯éš”ç¦»çš„ï¼‰ã€‚
- å¦‚æœå®¢æˆ·ç«¯ä¼ çš„æ˜¯è·¯å¾„ï¼Œç­‰äºæš´éœ²äº†æœåŠ¡ç«¯çš„æ–‡ä»¶ç³»ç»Ÿï¼Œå¸¦æ¥å¾ˆå¤§çš„å®‰å…¨é£é™©ã€‚
- åœ¨å¤šå°æœºå™¨ã€å¤šå‰¯æœ¬éƒ¨ç½²æ—¶ï¼Œæœ¬åœ°è·¯å¾„ä¸åŒï¼Œæ ¹æœ¬æ‰¾ä¸åˆ°åŒä¸€ä¸ªæ–‡ä»¶ã€‚
- **æ­£ç¡®åšæ³•**ï¼šè¦ä¹ˆå®¢æˆ·ç«¯æŠŠäºŒè¿›åˆ¶ç›´æ¥ä¼ ï¼Œè¦ä¹ˆå‰ç«¯ç›´ä¼ åˆ°å¯¹è±¡å­˜å‚¨ï¼ˆS3ã€MinIOã€OSSï¼‰ï¼Œç„¶åæŠŠé“¾æ¥å‘Šè¯‰åç«¯ã€‚
- ğŸ‘‰ **gRPC** é‡Œå¯ä»¥ä¼ å°æ–‡ä»¶ï¼Œæˆ–è€…ä¼ åˆ‡ç‰‡æµå¼ä¼ è¾“ï¼ˆè¦å®ç° `stream`ï¼‰ï¼Œä½†å¤§æ–‡ä»¶æ¨èç”¨ç›´ä¼ ã€‚
- ğŸ‘‰ æ‰€ä»¥æœ€å¼€å§‹ç›´æ¥ä¼ è·¯å¾„ï¼Œæ²¡æ„ä¹‰ä¸”æœ‰å®‰å…¨é£é™©ã€‚
- 
- gRPC åè®®è¦æ±‚ä½ åœ¨è¯·æ±‚ä¸­ç›´æ¥æ”¾ç½®æ–‡ä»¶çš„äºŒè¿›åˆ¶æ•°æ®ï¼Œ
    
    è€Œ **â€œè·¯å¾„â€åªæ˜¯å­—ç¬¦ä¸²ï¼Œä¸åŒ…å«çœŸå®æ–‡ä»¶å†…å®¹**ï¼Œ
    
    gRPC æœåŠ¡ç«¯ä¹Ÿæ²¡æœ‰æƒé™è®¿é—®å®¢æˆ·ç«¯ï¼ˆæˆ– Postmanï¼‰çš„æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿå»è¯»æ­¤è·¯å¾„ã€‚
    

> åš if in.Data == nil { è¯»å–è·¯å¾„è¯»å…¥ []byte }
> 
> 
> è¿™åªèƒ½åœ¨**æœåŠ¡ç«¯**ç¡¬ç¼–ç ç”¨æœ¬åœ°æ–‡ä»¶åšè°ƒè¯•ï¼ˆå³åªèƒ½ç”¨äºæœåŠ¡ç«¯æœ¬åœ°å¼€å‘å•æµ‹ï¼‰ï¼Œ
> 
> **æ— æ³•ç”¨äºçœŸå®ä¸Šä¼ **ï¼Œå› ä¸ºç”¨æˆ·ä¸Šä¼ åœºæ™¯ä¸‹æœåŠ¡å™¨å¹¶ä¸æŒæœ‰ç”¨æˆ·æœ¬åœ°æ–‡ä»¶è·¯å¾„å’Œæƒé™ã€‚
> 
> ### **ä¸ºä»€ä¹ˆä¸é€‚åˆç”Ÿäº§ï¼š**
> 
> - ç”¨æˆ·ä¸Šä¼ è§†é¢‘æ—¶ä¸ä¼šæŠŠæ–‡ä»¶è·¯å¾„å‘ç»™ä½ ï¼Œè€Œæ˜¯ä¸Šä¼ çœŸå®æ–‡ä»¶äºŒè¿›åˆ¶ã€‚
> - è·¯å¾„ä¸Šä¼ åªé€‚åˆå¼€å‘é˜¶æ®µåšæœ¬åœ°å‡æ•°æ®è°ƒè¯•ï¼Œä¸å¯æ‰©å±•åˆ°ç”¨æˆ·çœŸå®ä¸Šä¼ ã€‚
> - å®ƒä¸æ ‡å‡†çš„ HTTP ä¸Šä¼ ã€å‰ç«¯ç›´ä¼  OSS/MinIO çš„ä¸Šä¼ æ¨¡å¼å®Œå…¨ä¸å…¼å®¹ã€‚
> - ä»¥åä½ å¯¹æ¥ iOS/Android/Web SDK æ—¶éƒ½æ— æ³•ä½¿ç”¨è¿™ç§æ–¹å¼ä¸Šä¼ ã€‚

</aside>

<aside>
ğŸ’¡

`Gin` ç”¨çš„æ˜¯ **HTTP åè®®**ï¼Œå®ƒå¤©ç„¶æ”¯æŒæµè§ˆå™¨/å®¢æˆ·ç«¯é€šè¿‡ `multipart/form-data` ç›´æ¥ä¸Šä¼ æ–‡ä»¶ï¼ˆæ–‡ä»¶å­—æ®µä»¥ `Content-Type: multipart/form-data` ä¼ ï¼‰ã€‚

æ‰€ä»¥ï¼š

- å®¢æˆ·ç«¯ä¼ çš„æ˜¯ **çœŸå®çš„æ–‡ä»¶å†…å®¹**ï¼Œä¸æ˜¯è·¯å¾„ï¼ŒæœåŠ¡ç«¯é€šè¿‡ `c.FormFile("file")` ä» `POST` body ä¸­æ‹¿åˆ°äºŒè¿›åˆ¶æ–‡ä»¶æµï¼Œè¿™æ²¡å®‰å…¨éšæ‚£ã€‚
- Gin çš„è·¯ç”±ç›´æ¥æ¥æ”¶æ–‡ä»¶æµï¼Œæ–‡ä»¶æµåªå­˜åœ¨äºè¯·æ±‚é‡Œï¼Œ**æ²¡æœ‰è·¯å¾„ä¾èµ–**ï¼Œè·¨å®¹å™¨ã€è·¨å¤šå‰¯æœ¬éƒ½æ²¡é—®é¢˜ã€‚

æ‰€ä»¥ç”¨ Gin åšæ–‡ä»¶ä¸Šä¼ ï¼Œè·Ÿæµè§ˆå™¨è¡¨å•ä¸Šä¼ ä¸€ä¸ªåŸç†ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆç”Ÿäº§é‡Œå¤§æ–‡ä»¶ç›´ä¼ éƒ½ä¼šèµ° HTTPï¼Œä¸Šä¼ å®Œå†å‘Šè¯‰åç«¯ã€‚

- Gin èƒ½â€œç›´æ¥ä¸Šä¼ æ–‡ä»¶â€
- ç¬¦åˆç”¨æˆ·çœŸå®ä¸Šä¼ åœºæ™¯
- æ”¯æŒå¤§æ–‡ä»¶åˆ†ç‰‡ã€æ–­ç‚¹ç»­ä¼ ã€å‰ç«¯ç›´ä¼ ç­‰å¯æ‰©å±•åŠŸèƒ½
</aside>

1. åˆå§‹åŒ–ginæœåŠ¡
    
    ```sql
    func NewGinServer() *gin.Engine {
    	r := gin.Default()
    
    	// ä¸Šä¼ è§†é¢‘æ¥å£
    	r.POST("/api/video/upload", func(c *gin.Context) {
    		service.GlobalVideoService.UploadVideoGin(c)
    	})
    
    	return r
    }
    
    	// å¯åŠ¨ Gin server
    	go func() {
    		r := server.NewGinServer()
    		if err := r.Run(":8090"); err != nil {
    			panic(err)
    		}
    	}()
    ```
    
2. giné€»è¾‘
    1. ç»‘å®švideoservice
        
        <aside>
        ğŸ’¡
        
        - åœ¨ Kratos æ¶æ„ä¸‹ï¼š
            - æ‰€æœ‰ Usecaseã€Repoã€MinioUploaderã€JWTManager ç­‰ä¾èµ–éƒ½é€šè¿‡ `wire` æ„é€ åˆ° `VideoService` ä¸­ã€‚
            - å¦‚æœä½ åœ¨ Gin é‡Œè‡ªå·± newï¼Œå°±ä¼šå¤±å»é…ç½®ã€æ—¥å¿—ã€ä¸Šä¸‹æ–‡ç­‰é›†ä¸­ç®¡ç†ã€‚
            - æ— æ³•ä¿è¯ä¸ gRPC ä¾§è°ƒç”¨è¡Œä¸ºä¸€è‡´ï¼ˆå¦‚ç»Ÿä¸€ token æ ¡éªŒã€ä¸Šä¼ é€»è¾‘ã€ä¸šåŠ¡æµï¼‰ã€‚
            - `VideoService` æ—¢å¯ä»¥è¢« gRPC è°ƒï¼Œä¹Ÿå¯ä»¥è¢« HTTP è°ƒï¼Œå®Œå…¨ä¸€æ ·çš„ä¸šåŠ¡é€»è¾‘ï¼Œåªæ˜¯å…¥å£ä¸åŒã€‚
            - æ‰€ä»¥æ‰éœ€è¦ï¼š`BindVideoService` è®©å…¨å±€å¯ç”¨ï¼ŒGin åªç®¡æ‹¿åˆ°å®ƒè°ƒç”¨ã€‚
            
            âœ… ä¿æŒ
            
            **Gin å’Œ gRPC è°ƒç”¨çš„ä¸šåŠ¡é€»è¾‘å®Œå…¨ä¸€è‡´**
            
            ï¼ˆåŒä¸€ä¸ª
            
            ```
            VideoService
            ```
            
            ï¼‰
            
            âœ… ä¾¿äºåç»­åšæ¥å£ç½‘å…³ã€é™æµã€ç›‘æ§ã€Tracing
            
            âœ… ä¿ç•™ Kratos é¡¹ç›®çš„ä¸€è‡´æ€§
            
            âœ… æ–¹ä¾¿å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•
            
            âœ… é¿å…å†™ä¸¤ä»½é‡å¤ä¸Šä¼ é€»è¾‘
            
        </aside>
        
        ```sql
        var GlobalVideoService *VideoService
        
        func BindVideoService(svc *VideoService) {
        	GlobalVideoService = svc
        }
        
        func newAppWithService(
        	logger log.Logger,
        	gs *grpc.Server,
        	hs *http.Server,
        	videoService *service.VideoService,
        ) (*kratos.App, func(), error) {
        	// ç»‘å®šå¯ä¾› Gin ä½¿ç”¨çš„å…¨å±€ VideoService
        	service.BindVideoService(videoService)
        
        	app := newApp(logger, gs, hs)
        	cleanup := func() {
        		log.NewHelper(logger).Info("cleanup called")
        	}
        	return app, cleanup, nil
        }
        
        // wireApp init kratos application.
        func wireApp(*conf.Server, *conf.Data, log.Logger, *conf.JWT, *conf.Data_MinIO) (*kratos.App, func(), error) {
        	panic(wire.Build(server.ProviderSet, data.ProviderSet, biz.ProviderSet, service.ProviderSet, pkg.ProviderSet, newAppWithService))
        }
        ```
        
    2. è·å–æ•°æ®
        
        ```sql
        file, err := c.FormFile("file")
        token := c.PostForm("token")
        refreshToken := c.PostForm("refreshToken")
        ```
        
    3. è¯»å–æ–‡ä»¶
        
        ```sql
        f, err := file.Open()
        defer f.Close()
        data, err := io.ReadAll(f)
        ```
        
    4. grpcè¯·æ±‚
        
        ```sql
        reply, err := s.UploadVideo(c, &v1.UploadVideoRequest{
        		Data:         data,
        		Filename:     file.Filename,
        		Token:        token,
        		RefreshToken: refreshToken,
        	})
        ```
        
3. grpc å¤„ç†
    1. æ ¡éªŒå‚æ•°tokenï¼Œdataï¼Œfilename
    2. ä¸Šä¼ 
        
        ```sql
        reader := bytes.NewReader(in.Data)
        	playURL, err := s.uc.UploadVideo(ctx, objectName, reader, int64(len(in.Data)), "video/mp4")
        ```
        
    3. ç”Ÿæˆè§†é¢‘åœ°å€

## åˆ›å»ºè§†é¢‘

1. ç”Ÿæˆè§†é¢‘æ•°æ®åº“gen

```sql
package main

// gorm gen configure

import (
	"fmt"

	"gorm.io/driver/mysql"
	"gorm.io/gorm"

	"gorm.io/gen"
)

const MySQLDSN = "root:root@tcp(127.0.0.1:3306)/tiktok?charset=utf8mb4&parseTime=True"

func connectDB(dsn string) *gorm.DB {
	db, err := gorm.Open(mysql.Open(dsn))
	if err != nil {
		panic(fmt.Errorf("connect db fail: %w", err))
	}
	return db
}

func main() {
	// æŒ‡å®šç”Ÿæˆä»£ç çš„å…·ä½“ç›¸å¯¹ç›®å½•(ç›¸å¯¹å½“å‰æ–‡ä»¶)ï¼Œé»˜è®¤ä¸ºï¼š./query
	// é»˜è®¤ç”Ÿæˆéœ€è¦ä½¿ç”¨WithContextä¹‹åæ‰å¯ä»¥æŸ¥è¯¢çš„ä»£ç ï¼Œä½†å¯ä»¥é€šè¿‡è®¾ç½®gen.WithoutContextç¦ç”¨è¯¥æ¨¡å¼
	g := gen.NewGenerator(gen.Config{
		// é»˜è®¤ä¼šåœ¨ OutPath ç›®å½•ç”ŸæˆCRUDä»£ç ï¼Œå¹¶ä¸”åŒç›®å½•ä¸‹ç”Ÿæˆ model åŒ…
		// æ‰€ä»¥OutPathæœ€ç»ˆpackageä¸èƒ½è®¾ç½®ä¸ºmodelï¼Œåœ¨æœ‰æ•°æ®åº“è¡¨åŒæ­¥çš„æƒ…å†µä¸‹ä¼šäº§ç”Ÿå†²çª
		// è‹¥ä¸€å®šè¦ä½¿ç”¨å¯ä»¥é€šè¿‡ModelPkgPathå•ç‹¬æŒ‡å®šmodel packageçš„åç§°
		OutPath: "./internal/data/query",
		/* ModelPkgPath: "dal/model"*/

		// gen.WithoutContextï¼šç¦ç”¨WithContextæ¨¡å¼
		// gen.WithDefaultQueryï¼šç”Ÿæˆä¸€ä¸ªå…¨å±€Queryå¯¹è±¡Q
		// gen.WithQueryInterfaceï¼šç”ŸæˆQueryæ¥å£
		Mode: gen.WithDefaultQuery | gen.WithQueryInterface,
	})

	// é€šå¸¸å¤ç”¨é¡¹ç›®ä¸­å·²æœ‰çš„SQLè¿æ¥é…ç½®db(*gorm.DB)
	// éå¿…éœ€ï¼Œä½†å¦‚æœéœ€è¦å¤ç”¨è¿æ¥æ—¶çš„gorm.Configæˆ–éœ€è¦è¿æ¥æ•°æ®åº“åŒæ­¥è¡¨ä¿¡æ¯åˆ™å¿…é¡»è®¾ç½®
	g.UseDB(connectDB(MySQLDSN))

	// ä»è¿æ¥çš„æ•°æ®åº“ä¸ºæ‰€æœ‰è¡¨ç”ŸæˆModelç»“æ„ä½“å’ŒCRUDä»£ç 
	// ä¹Ÿå¯ä»¥æ‰‹åŠ¨æŒ‡å®šéœ€è¦ç”Ÿæˆä»£ç çš„æ•°æ®è¡¨
	g.ApplyBasic(g.GenerateAllTable()...)

	// æ‰§è¡Œå¹¶ç”Ÿæˆä»£ç 
	g.Execute()
}

```

1. é€»è¾‘
    1. æ ¡éªŒå‚æ•°ï¼ˆtokenã€titleï¼‰
    2. ä¸Šä¼ è§†é¢‘
    3. è§†é¢‘titleå’Œdescriptionã€tagçš„æ•æ„Ÿè¯è¿‡æ»¤ï¼Œé•¿åº¦é™åˆ¶ TODO
    4. ç”Ÿæˆè§†é¢‘çš„video_idï¼ˆé›ªèŠ±ç®—æ³•ï¼‰

## è·å–ç”¨æˆ·è§†é¢‘åˆ—è¡¨

1. å‚æ•°æ ¡éªŒ
    1. è·å–tokenä¸­çš„æŸ¥é˜…ç”¨æˆ·id
    2. æŸ¥æ‰¾æŸ¥é˜…ç”¨æˆ·idæ˜¯å¦åˆæ³•
    3. æŸ¥æ‰¾è¢«æŸ¥é˜…ç”¨æˆ·idæ˜¯å¦åˆæ³•
        1. rpcè°ƒç”¨ï¼ˆconsulï¼‰user-serviceæ³¨å†Œ
        
        ```sql
        // proto å®¹å™¨ä¸­çš„consulèƒ½æ£€æµ‹åˆ°
        server:
          http:
            addr: 0.0.0.0:8080
            timeout: 1s
          grpc:
            addr: 0.0.0.0:9090
            timeout: 1s 
        registry:
          consul:
            addr: 127.0.0.1:8500
        service:
          name: user-service
          version: v1.0.0
        
        // cmd
        
        func newApp(logger log.Logger, gs *grpc.Server, hs *http.Server, consulAddr string) *kratos.App {
        	// new consul client
        	**consulCfg := api.DefaultConfig()
        	consulCfg.Address = consulAddr
        	client, err := api.NewClient(consulCfg)
        	if err != nil {
        		panic(err)
        	}
        	reg := consul.New(client)**
        
        	return kratos.New(
        		kratos.ID(id),
        		kratos.Name(Name),
        		kratos.Version(Version),
        		kratos.Metadata(map[string]string{}),
        		kratos.Logger(logger),
        		kratos.Server(
        			gs,
        			hs,
        		),
        		kratos.Registrar(reg),
        	)
        }
        
        	consulAddr := bc.Registry.Consul.Addr
        	Name = bc.Service.Name
        	Version = bc.Service.Version
        	// è¿™é‡Œæœ‰ä¸ªè¸©å‘
        	id = fmt.Sprintf("%s-%s", Name, bc.Server.Http.Addr)
        	// ä¸ç„¶consulä¸€ç›´æœ‰é—®é¢˜
        	
        	func NewData(c *conf.Data, logger log.Logger, jwt *pkg.JWTManager, upload *pkg.MinioUploader, db *gorm.DB, rdb *redis.Client, idg *pkg.IDGenerator, rr *consul.Registry) (*Data, func(), error) {
        	cleanup := func() {
        		log.NewHelper(logger).Info("closing the data resources")
        	}
        	query.SetDefault(db)
        
        	conn, err := grpc.DialInsecure(
        		context.Background(),
        		grpc.WithEndpoint(c.UserService.Endpoint),
        		grpc.WithDiscovery(rr),
        	)
        	if err != nil {
        		return nil, nil, err
        	}
        	return &Data{log: log.NewHelper(logger), jwt: jwt, uploade: upload, db: db, rdb: rdb, idg: idg, query: query.Q, UserClient: pbUser.NewUserServiceClient(conn)}, cleanup, nil
        }
        ```
        
    4. video-service
        
        ```go
        data: 
          user_service:
            endpoint: discovery:///user-service
        registry:
          consul:
            addr: 127.0.0.1:8500
        service:
          name: user-service
          version: v1.0.0
          
        // main
        	consulCfg := api.DefaultConfig()
        	consulCfg.Address = bc.Registry.Consul.Addr
        	client, err := api.NewClient(consulCfg)
        	if err != nil {
        		panic(err)
        	}
        	reg := consul.New(client)
        	
        	app, cleanup, err := wireApp(bc.Server, bc.Data, logger, bc.Jwt, bc.Data.Minio, bc.IdGen, reg)
        	
        	func newApp(logger log.Logger, gs *grpc.Server, hs *http.Server, reg *consul.Registry) *kratos.App {
        	return kratos.New(
        		kratos.ID(id),
        		kratos.Name(Name),
        		kratos.Version(Version),
        		kratos.Metadata(map[string]string{}),
        		kratos.Logger(logger),
        		kratos.Server(
        			gs,
        			hs,
        		),
        		kratos.Registrar(reg),
        	)
        }
        
        func wireApp(*conf.Server, *conf.Data, log.Logger, *conf.JWT, *conf.Data_MinIO, *conf.IDGen, *consul.Registry) (*kratos.App, func(), error) {
        	panic(wire.Build(server.ProviderSet, data.ProviderSet, biz.ProviderSet, service.ProviderSet, pkg.ProviderSet, newAppWithService))
        }
        
        ```
        
2. æ ¹æ®è¢«æŸ¥é˜…çš„ç”¨æˆ·idå»æŸ¥æ‰¾è§†é¢‘åˆ—è¡¨
    1. æŒ‰ç…§åˆ†é¡µæ¥è¿”å›

## æ¨¡ç³Šè·å–è§†é¢‘

1. æ ¹æ®titleæ¨¡ç³Šè·å–è§†é¢‘
2. ä»esä¸­æ¨¡ç³Šè·å–
3. ä»mysqlä¸­æ¨¡ç³Šè·å–ï¼ˆå…œåº•ï¼‰

# Feed-Service

è·å–è§†é¢‘æµ

1. æ¸¸å®¢æ¨¡å¼
2. éæ¸¸å®¢æ¨¡å¼ï¼ˆuser  service å¾®æœåŠ¡è°ƒç”¨ï¼‰
    1. è§£ætoken
    2. éªŒè¯token
3. è·å–è§†é¢‘æµ(æ‰¹é‡è¿”å›è§†é¢‘åˆ—è¡¨)
    1. æŸ¥è¯¢æ—¶é—´çš„èµ·ç‚¹
    2. æŸ¥è¯¢æ•°é‡ï¼Œå†æŸ¥è¯¢æ—¶é—´å‰å¤šå°‘ä¸ª
    3. æ•°æ®åº“æŸ¥è¯¢
    4. åæœŸï¼šæŒ‰æ—¶é—´å’Œçƒ­åº¦è®¡ç®—åˆ†æ•°æŸ¥è¯¢
4. è·å–è§†é¢‘ä½œè€…ä¿¡æ¯
    1. æ ¹æ®è§†é¢‘æµä¸­ä½œè€…idè·å–ä½œè€…ä¿¡æ¯
    2. user  service å¾®æœåŠ¡è°ƒç”¨ï¼Œæ‰¹é‡è·å–
5. ç‚¹èµä¿¡æ¯
    1. å½“å‰ç”¨æˆ·æ˜¯å¦ç‚¹èµ
6. ç”¨æˆ·å…³ç³»ä¿¡æ¯
    1. å½“å‰ç”¨æˆ·æ˜¯å¦æ˜¯ä½œè€…çš„ç²‰ä¸

# Favorite-service

```sql
CREATE TABLE IF NOT EXISTS `favorite` (
                                          `id` BIGINT UNSIGNED NOT NULL AUTO_INCREMENT COMMENT 'ä¸»é”®ID',
                                          `user_id` BIGINT UNSIGNED NOT NULL COMMENT 'ç”¨æˆ·ID',
                                          `video_id` BIGINT UNSIGNED NOT NULL COMMENT 'è§†é¢‘ID',
                                          `created_at` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'ç‚¹èµæ—¶é—´',
                                          `updated_at` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æ›´æ–°æ—¶é—´',
                                          PRIMARY KEY (`id`),
    UNIQUE KEY `idx_user_video` (`user_id`, `video_id`),
    INDEX `idx_video_id` (`video_id`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='ç”¨æˆ·ç‚¹èµè¡¨';

```

## ç‚¹èµ

1. å‚æ•°æ ¡éªŒ
    1. token
    2. ç‚¹èµç±»å‹
    3. ç‚¹èµè§†é¢‘çš„id
2. è§†é¢‘ç‚¹èµ
    1. ç±»å‹ä¸º1ç‚¹èµ
        1. åˆ¤æ–­ä¹‹å‰æ˜¯å¦æœ‰è¿‡æ“ä½œï¼Œå¹‚ç­‰
        2. äº‹åŠ¡ï¼Œç‚¹èµæ•°æ®åº“ï¼Œè§†é¢‘æ•°æ®åº“ç‚¹èµè®¡æ•°
    2. ç±»å‹ä¸º2å–æ¶ˆç‚¹èµ
        1. äº‹åŠ¡ï¼Œç‚¹èµæ•°æ®åº“åˆ é™¤ï¼Œè§†é¢‘æ•°æ®åº“ç‚¹èµè®¡æ•°-1

## è·å–ç”¨æˆ·ç‚¹èµåˆ—è¡¨

1. å‚æ•°æ ¡éªŒ
    1. è¢«æŸ¥è¯¢ç”¨æˆ·çš„id
    2. å½“å‰ç”¨æˆ·çš„idï¼Œtokenè§£æ
2. æ ¹æ®è¢«æŸ¥è¯¢ç”¨æˆ·idæŸ¥è¯¢ç‚¹èµçš„è§†é¢‘id
3. æ ¹æ®ç‚¹èµè§†é¢‘çš„idè·å–è§†é¢‘ä¿¡æ¯

<aside>
ğŸ’¡

// è¿™æ˜¯consulä¸­ä¹Ÿè¦ä¿®æ”¹çš„
`id = fmt.Sprintf("%s-%s", Name, bc.Server.Http.Addr)`

</aside>

# comment-service

```sql
CREATE TABLE IF NOT EXISTS `comment` (
                                         `id` BIGINT UNSIGNED NOT NULL AUTO_INCREMENT COMMENT 'ä¸»é”®ID',
                                         `user_id` BIGINT UNSIGNED NOT NULL COMMENT 'ç”¨æˆ·ID',
                                         `video_id` BIGINT UNSIGNED NOT NULL COMMENT 'è§†é¢‘ID',
                                         `parent_id` BIGINT UNSIGNED DEFAULT 0 COMMENT 'çˆ¶è¯„è®ºIDï¼Œ0è¡¨ç¤ºä¸€çº§è¯„è®º',
                                         `content` TEXT NOT NULL COMMENT 'è¯„è®ºå†…å®¹',
                                         `is_deleted` TINYINT(1) NOT NULL DEFAULT 0 COMMENT 'æ˜¯å¦åˆ é™¤ï¼š0-æœªåˆ é™¤ï¼Œ1-å·²åˆ é™¤',
    `created_at` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'è¯„è®ºæ—¶é—´',
    `updated_at` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æ›´æ–°æ—¶é—´',
    PRIMARY KEY (`id`),
    INDEX `idx_video_id` (`video_id`),
    INDEX `idx_user_id` (`user_id`),
    INDEX `idx_parent_id` (`parent_id`),
    INDEX `idx_video_created_at` (`video_id`, `created_at` DESC)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='è§†é¢‘è¯„è®ºè¡¨';

```

## åˆ›å»ºè¯„è®º

1. å‚æ•°æ ¡éªŒ
    1. è§†é¢‘id
    2. token
    3. æ“ä½œ
2. è§£ætoken
3. åˆ›å»ºè¯„è®º
    1. è§†é¢‘æ˜¯å¦å­˜åœ¨ï¼ˆrpcè°ƒç”¨ï¼‰
    2. æ ¹æ®æ“ä½œåˆ›å»ºæˆ–è€…åˆ é™¤è¯„è®º
        1. ç”Ÿæˆè¯„è®ºidï¼ˆé›ªèŠ±ç®—æ³•ï¼‰
        2. äº‹åŠ¡åˆ›å»ºè¯„è®º
            1. åˆ›å»ºè¯„è®ºï¼ˆcommentï¼‰
            2. æ›´æ–°è¯„è®ºæ€»æ•°ï¼ˆvideoï¼‰
            3. åˆ é™¤ä½¿ç”¨è½¯åˆ é™¤

## è·å–è§†é¢‘è¯„è®ºåˆ—è¡¨

1. å‚æ•°æ ¡éªŒ
    1. è§†é¢‘id
    2. token
2. è§£ætoken
3. è·å–è§†é¢‘è¯„è®ºåˆ—è¡¨
    1. è§†é¢‘æ˜¯å¦å­˜åœ¨
    2. è·å–è§†é¢‘è¯„è®ºåˆ—è¡¨

# relation-service

```sql
CREATE TABLE IF NOT EXISTS `relation` (
                                          `id` BIGINT UNSIGNED NOT NULL AUTO_INCREMENT COMMENT 'ä¸»é”®ID',
                                          `user_id` BIGINT UNSIGNED NOT NULL COMMENT 'ç”¨æˆ·ID',
                                          `to_user_id` BIGINT UNSIGNED NOT NULL COMMENT 'å…³æ³¨ç”¨æˆ·çš„ID',
                                          `created_at` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'å…³æ³¨æ—¶é—´',
                                          `updated_at` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æ›´æ–°æ—¶é—´',
                                          `deleted_at` DATETIME DEFAULT NULL COMMENT 'åˆ é™¤æ—¶é—´',
                                          PRIMARY KEY (`id`),
    UNIQUE KEY `uniq_user_to_user` (`user_id`, `to_user_id`),
    INDEX `idx_user_id` (`user_id`),
    INDEX `idx_to_user_id` (`to_user_id`),
    INDEX `idx_deleted_at` (`deleted_at`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='ç”¨æˆ·å…³ç³»è¡¨';

```

## å…³æ³¨æ“ä½œ

1. å‚æ•°æ ¡éªŒ
    1. è¡Œä¸ºå‚æ•°ï¼ˆaction_typeï¼‰å…³æ³¨ï¼š1ï¼Œ å–æ¶ˆå…³æ³¨ï¼š2
    2. tokenè§£æâ€”>userid
    3. è¢«å…³æ³¨å¯¹è±¡(to_user_id)
2. å…³æ³¨é€»è¾‘
    1. to_user_id æ˜¯å¦å­˜åœ¨ (rpc user-service)
    2. action_typeï¼š1
        1. åˆ›å»ºå…³æ³¨å…³ç³»ï¼ˆuser_idï¼Œto_user_idï¼‰
            1. æ˜¯å¦å·²ç»å»ºç«‹
            2. åˆ›å»ºå…³ç³»
            3. æ›´æ–°è¢«å…³æ³¨ç”¨æˆ·ç²‰ä¸æ•°
            4. æ›´æ–°å½“å‰ç”¨æˆ·å…³æ³¨æ•°é‡
    3. action_typeï¼š2
        1. åˆ é™¤å…³æ³¨å…³ç³»
            1. æ˜¯å¦å­˜åœ¨å…³ç³»
            2. åˆ é™¤å…³ç³»
            3. æ›´æ–°è¢«å…³æ³¨ç”¨æˆ·ç²‰ä¸æ•°
            4. æ›´æ–°å½“å‰ç”¨æˆ·å…³æ³¨æ•°é‡
3. è¿”å›å“åº”

## è·å–å…³æ³¨åˆ—è¡¨

1. å‚æ•°æ ¡éªŒ
    1. user_id
    2. token
2. è·å–å…³æ³¨åˆ—è¡¨é€»è¾‘
    1. udsr_idæ˜¯å¦å­˜åœ¨
    2. è·å–user_idå…³æ³¨åˆ—è¡¨
3. è¿”å›ç›¸åº”

## è·å–å…³ç³»

1. ä»redisä¸­æŸ¥è¯¢å…³ç³»

1. ä»esä¸­æŸ¥è¯¢å…³ç³»
2. ä»mysqlä¸­æŸ¥è¯¢å…³ç³»ï¼ˆå…œåº•ï¼‰

# job-service

è´Ÿè´£kafka-elasticsearchæ•°æ®æµåŠ¨

## kafka

1. mysql
    
    ```sql
    /etc/mysql/my.cnf
    [mysqld]
    log-bin=mysql-bin # å¼€å¯ binlog
    binlog-format=ROW # é€‰æ‹© ROW æ¨¡å¼
    server_id=1 # é…ç½® MySQL replaction éœ€è¦å®šä¹‰ï¼Œä¸è¦å’Œ canal çš„ slaveId é‡å¤
    
    //æŸ¥çœ‹
    show variables like 'log_bin'; -> on
    show variables like 'binlog_format'; -> row
    
    CREATE USER 'ysh'@'%' IDENTIFIED BY 'ysh';
    GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'ysh'@'%';
    FLUSH PRIVILEGES;
    ```
    
2. canal
    
    ```sql
    docker pull canal/canal-server:latest
    
    // å¯åŠ¨å®¹å™¨
    docker run -d \
      --name canal-server \
      --add-host=host.docker.internal:host-gateway \
      canal/canal-server:latest
    
    // è¿›å…¥å®¹å™¨
    docker exec -it canal-server /bin/bash
    
    // ä¿®è¯¥é…ç½®
    vi canal-server/conf/example/instance.properties
    
    canal.instance.master.address=host.docker.internal:3306
    
    canal.instance.tsdb.dbUsername=canal
    canal.instance.tsdb.dbPassword=password // ä¸Šé¢çš„nameå’Œpassword
    
    ```
    
3. kafka
    
    ```sql
    version: '2.1'
    
    services:
      zoo1:
        image: confluentinc/cp-zookeeper:7.3.2
        hostname: zoo1
        container_name: zoo1
        ports:
          - "2181:2181"
        environment:
          ZOOKEEPER_CLIENT_PORT: 2181
          ZOOKEEPER_SERVER_ID: 1
          ZOOKEEPER_SERVERS: zoo1:2888:3888
    
      tiktok-kafka:
        image: confluentinc/cp-kafka:7.3.2
        hostname: tiktok-kafka
        container_name: tiktok-kafka    # ğŸ‘ˆ å›ºå®šå®¹å™¨å
        ports:
          - "9092:9092"
          - "19092:19092"
          - "9999:9999"
          - "29092:29092"   # ğŸ‘ˆ æ–°å¢ï¼Œä¾›å®¹å™¨ä¸­å…¶ä»–æœåŠ¡ï¼ˆå¦‚ Canalï¼‰è®¿é—®"
        environment:
          KAFKA_ADVERTISED_LISTENERS: INTERNAL://tiktok-kafka:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
          KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
          KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
          KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
          KAFKA_BROKER_ID: 1
          KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
          KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
          KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
          KAFKA_JMX_PORT: 9999
          KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
          KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
          KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
        depends_on:
          - zoo1
    
      kafka-ui:
        container_name: kafka-ui
        image: provectuslabs/kafka-ui:latest
        extra_hosts:
          - "host.docker.internal:host-gateway"
        ports:
          - 18080:8080
        depends_on:
          - tiktok-kafka
        environment:
          DYNAMIC_CONFIG_ENABLED: "TRUE"
    
    ```
    
4. é…ç½®
    
    ```sql
    vi canal-server/conf/example/instance.properties
    
    canal.mq.dynamicTopic=mytest,.*,mytest.user,mytest\\..*,.*\\..* // æŒ‰éœ€è¦ä¿®æ”¹
    ä¾‹å¦‚ï¼š
    topic3:commit\\..* //commitæ˜¯æ•°æ®åº“
    
    // åŠ¨æ€é…ç½®
    
    # mq config
    canal.mq.topic=default_topic_if_no_match
    # dynamic topic route by schema or table regex
    canal.mq.flatMessage=true
    canal.mq.dynamicTopic= tiktok_users:tiktok.users,tiktok_relation:tiktok.relation
    canal.mq.partition=0
    
    # table regex
    # canal.instance.filter.regex=.*\\..*
    canal.instance.filter.regex=tiktok\\.(users|relation)
    
    vi /home/admin/canal-server/conf/canal.properties
    
    # å¯é€‰é¡¹: tcp(é»˜è®¤), kafka,RocketMQ,rabbitmq,pulsarmq
    canal.serverMode = kafka
    
    ##################################################
    #########                    Kafka                   #############
    ##################################################
    # æ­¤å¤„é…ç½®ä¿®æ”¹ä¸ºä½ çš„Kafkaç¯å¢ƒåœ°å€
    kafka.bootstrap.servers = host.docker.internal:29092
    ```
    
    ```sql
    	go get github.com/segmentio/kafka-go
    ```
    

## Elasticsearch

```sql
services:
  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:8.9.1
    environment:
      - node.name=elasticsearch
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - 9200:9200
      - 9300:9300
    networks:
      - elastic
  kibana:
    image: docker.elastic.co/kibana/kibana:8.9.1
    container_name: kibana
    ports:
      - 5601:5601
    networks:
      - elastic
    depends_on:
      - elasticsearch

networks:
  elastic:
```

```sql
go get github.com/elastic/go-elasticsearch/v8@latest
```

## job-service

1. æœåŠ¡é…ç½®
    
    ```sql
    
    message ElasticsearchIndex {
      string topic = 1;
      string index = 2;
    }
    
    message Elasticsearch {
      repeated string addresses = 1;
      repeated ElasticsearchIndex indices = 2;
    }
    
    message Kafka {
      repeated string brokers = 1;
      string group_id = 2;
      repeated string topics = 3;
    }
    
    elasticsearch:
      addresses:
        - "http://localhost:9200"
      indices:
        - topic: "tiktok_users"
          index: "tiktok_users"
        - topic: "tiktok_relation"
          index: "tiktok_relation"
    
    kafka:
      brokers:
        - "localhost:9092"
      group_id: "tiktok_sync_group"
      topics:
        - "tiktok_users"
        - "tiktok_relation"
    ```
    
2. jobå¾®æœåŠ¡
    1. è¿æ¥esï¼Œè¿™é‡Œçš„esç›¸å½“äºä¸€ä¸ªæ¶ˆè´¹è€…ï¼Œè®¢é˜…äº†3ä¸ªtopicï¼Œä½†æ¯æ¬¡æ¶ˆè´¹éƒ½æ˜¯æœ‰åºçš„
    2. kafka
        1. brokerï¼ˆèŠ‚ç‚¹ï¼‰
        2. topicï¼ˆä¸»é¢˜ï¼‰
        3. group_idï¼ˆæ¶ˆè´¹è€…ç»„ï¼‰ï¼šå¦‚æœæˆ‘åŒæ—¶å¯åŠ¨å¤šä¸ªjobå¾®æœåŠ¡ï¼Œå°±èƒ½ç»„æˆä¸€ä¸ªæ¶ˆè´¹è€…ç»„
    3. ä»kafkaä¸­è¯»å–å¹¶å†™å…¥es
        1. kafkaçš„æ•°æ®çš„æ¶ˆæ¯ç»“æ„ä½“
        2. è¯»å–åˆ°kafkaä¸­çš„ä¿¡æ¯
        3. æ ¹æ®ç»™å®šä¿¡æ¯æ‹¿åˆ°esä¸­çš„index
        4. ååºåˆ—åŒ–
        5. æå–å”¯ä¸€idï¼ˆå¹‚ç­‰ï¼‰
        6. æ ¹æ®æ¶ˆæ¯ä¸­çš„ç±»å‹è¿›è¡Œæ“ä½œes

```sql
package job

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"github.com/elastic/go-elasticsearch/v8"
	"github.com/go-kratos/kratos/v2/log"
	"github.com/segmentio/kafka-go"
	"job-service/internal/conf"
)

// æ¶ˆæ¯ç»“æ„ä½“ (canal æ ¼å¼)
type Msg struct {
	Type     string `json:"type"`
	Database string `json:"database"`
	Table    string `json:"table"`
	IsDdl    bool   `json:"isDdl"`
	Data     []map[string]interface{}
}

// ES å®¢æˆ·ç«¯å°è£…
type EsClient struct {
	*elasticsearch.TypedClient
}

type Server interface {
	Start(context.Context) error
	Stop(context.Context) error
}

// ä½œä¸š Worker,ç”¨äºæ¶ˆè´¹ Kafka æ¶ˆæ¯å¹¶åŒæ­¥è‡³ Elasticsearch
type JobWork struct {
	kafkaReader   *kafka.Reader
	esClient      *EsClient
	topicIndexMap map[string]string
	log           *log.Helper
}

func NewJobWrok(kafkaReader *kafka.Reader, esClient *EsClient, conf *conf.Elasticsearch, logger log.Logger) *JobWork {
	topicIndexMap := make(map[string]string)
	for _, idx := range conf.Indices {
		topicIndexMap[idx.Topic] = idx.Index
	}
	return &JobWork{
		kafkaReader:   kafkaReader,
		esClient:      esClient,
		topicIndexMap: topicIndexMap,
		log:           log.NewHelper(logger),
	}
}

// kafka
// Kafka Reader
func NewKafkaReader(c *conf.Kafka) *kafka.Reader {
	return kafka.NewReader(kafka.ReaderConfig{
		Brokers:     c.Brokers,
		GroupTopics: c.Topics,
		GroupID:     c.GroupId,
	})
}

// elsaticsearch
func NewESClient(conf *conf.Elasticsearch) (*EsClient, error) {
	// ES é…ç½®
	c := elasticsearch.Config{Addresses: conf.Addresses}

	// åˆ›å»ºå®¢æˆ·ç«¯è¿æ¥
	client, err := elasticsearch.NewTypedClient(c)
	if err != nil {
		return nil, err
	}

	return &EsClient{
		TypedClient: client,
	}, nil
}

// å¯åŠ¨æ¶ˆè´¹å¾ªç¯ï¼Œå°† canal->kafka çš„å˜æ›´æ¶ˆæ¯åŒæ­¥åˆ° Elasticsearch
func (jw JobWork) Start(ctx context.Context) error {
	jw.log.WithContext(ctx).Info("job work start")

	// 1. ä»kafkaä¸­è·å–MySQLä¸­çš„æ•°æ®å˜æ›´æ¶ˆæ¯
	// æ¥æ”¶æ¶ˆæ¯
	for {
		// è¯»å– Kafka æ¶ˆæ¯
		m, err := jw.kafkaReader.ReadMessage(ctx)
		// å¦‚æœä¸Šå±‚ ctx è¢«å–æ¶ˆï¼Œä¼˜é›…é€€å‡º
		if errors.Is(err, context.Canceled) {
			return nil
		}
		if err != nil {
			jw.log.Errorf("read message failed:%v\n", err)
			break
		}
		jw.log.WithContext(ctx).Infof("message at offset %d: %s = %s\n", m.Offset, string(m.Key), string(m.Value))

		// æ ¹æ®å½“å‰ topic æŸ¥æ‰¾å¯¹åº”ç´¢å¼•
		index, ok := jw.topicIndexMap[m.Topic]
		if !ok {
			jw.log.WithContext(ctx).Errorf("no index mapping for topic: %s", m.Topic)
			continue
		}

		// ååºåˆ—åŒ– canal æ¶ˆæ¯
		msg := new(Msg)
		if err := json.Unmarshal(m.Value, msg); err != nil {
			jw.log.WithContext(ctx).Errorf("unmarshal message failed:%v\n", err)
			continue
		}

		// éå†å˜æ›´çš„è¡Œæ•°æ®
		for _, data := range msg.Data {
			// æå–å”¯ä¸€ IDï¼ˆç”¨äº ES çš„æ–‡æ¡£ _idï¼‰
			docID := jw.extractID(data)
			if docID == "" {
				jw.log.WithContext(ctx).Error("missing id in message, skipping")
				continue
			}

			// æ ¹æ® canal ç±»å‹é€‰æ‹©æ’å…¥æˆ–æ›´æ–°
			switch msg.Type {
			case "INSERT":
				jw.indexDocument(ctx, index, docID, data)
			case "UPDATE":
				jw.updateDocument(ctx, index, docID, data)
			default:
				jw.log.WithContext(ctx).Infof("unsupported message type: %s, skipping", msg.Type)
			}
		}
	}
	return nil
}

// // æå–å”¯ä¸€ idï¼Œç”¨äº ES å†™å…¥/æ›´æ–°æ—¶åšæ–‡æ¡£ _idï¼Œä¾¿äºå¹‚ç­‰å†™å…¥
func (jw *JobWork) extractID(data map[string]interface{}) string {
	if id, ok := data["id"]; ok {
		switch v := id.(type) {
		case string:
			return v
		case float64:
			// Canal è½¬æ¢æ—¶å¯èƒ½æ˜¯ float64ï¼Œè½¬å›å­—ç¬¦ä¸²
			return fmt.Sprintf("%.0f", v)
		}
	}
	return ""
}

// åœ¨ Elasticsearch ä¸­æ’å…¥æ–‡æ¡£ï¼ˆå¹‚ç­‰å†™å…¥ï¼‰
func (jw *JobWork) indexDocument(ctx context.Context, index, id string, data map[string]interface{}) {
	_, err := jw.esClient.Index(index).Id(id).Document(data).Do(ctx)
	if err != nil {
		jw.log.WithContext(ctx).Errorf("index document failed: %v", err)
	} else {
		jw.log.WithContext(ctx).Infof("indexed document id=%s into index=%s", id, index)
	}
}

// åœ¨ Elasticsearch ä¸­æ›´æ–°æ–‡æ¡£ï¼ˆå¹‚ç­‰æ›´æ–°ï¼‰
func (jw *JobWork) updateDocument(ctx context.Context, index, id string, data map[string]interface{}) {
	_, err := jw.esClient.Update(index, id).Doc(data).DocAsUpsert(true).Do(ctx)
	if err != nil {
		jw.log.WithContext(ctx).Errorf("update document failed: %v", err)
	} else {
		jw.log.WithContext(ctx).Infof("updated document id=%s in index=%s", id, index)
	}
}

func (jw JobWork) Stop(ctx context.Context) error {
	jw.log.WithContext(ctx).Info("job work stop")
	return jw.kafkaReader.Close()
}
```

1. æœåŠ¡æ³¨å†Œ

```sql
package job

import "github.com/google/wire"

var ProviderSet = wire.NewSet(NewJobWrok, NewESClient, NewKafkaReader)

// wireApp init kratos application.
func wireApp(*conf.Server, *conf.Data, *conf.Elasticsearch, *conf.Kafka, log.Logger) (*kratos.App, func(), error) {
	panic(wire.Build(server.ProviderSet, data.ProviderSet, biz.ProviderSet, service.ProviderSet, job.ProviderSet, newApp))
}

func newApp(logger log.Logger, gs *grpc.Server, hs *http.Server, js *job.JobWork) *kratos.App {
	return kratos.New(
		kratos.ID(id),
		kratos.Name(Name),
		kratos.Version(Version),
		kratos.Metadata(map[string]string{}),
		kratos.Logger(logger),
		kratos.Server(
			//gs,
			//hs,
			js,
		),
	)
}

app, cleanup, err := wireApp(bc.Server, bc.Data, bc.Elasticsearch, bc.Kafka, logger)
```

1. esè°ƒç”¨
    1. å¯¹æŸ¥è¯¢çš„æ•°æ®ï¼Œå…ˆåˆ°ç¼“å­˜ä¸­æŸ¥è¯¢
    2. ç¼“å­˜ä¸­æ²¡æœ‰åˆ°esä¸­æŸ¥è¯¢
        
        ```go
        resq, err := r.data.es.Search().Index(r.data.esIndex).Query(
        		&types.Query{
        			Bool: &types.BoolQuery{
        				Must: []types.Query{
        					{
        						Term: map[string]types.TermQuery{
        							"user_id": {Value: userID},
        						},
        					},
        					{
        						Term: map[string]types.TermQuery{
        							"to_user_id": {
        								Value: toUserID},
        						},
        					},
        				},
        			},
        		}).Do(ctx)
        ```
        
    3. esä¸­æ²¡æœ‰åˆ°sqlä¸­æŸ¥è¯¢ï¼ˆå…œåº•ï¼‰
    4. å›å¡«ç¼“å­˜
2. è¡¥å……
    
    å¦‚æœè¯´æˆ‘åœ¨canalä¸­è®¾ç½®å¤šä¸ªåˆ†åŒºï¼ˆå¦‚æœä¸æŒ‡å®šï¼Œcanalä¼šé»˜è®¤åˆ†ç»™åˆ†åŒº0ï¼‰ï¼Œå¹¶å¯ç”¨hashæ¥è¿›è¡Œåˆ†åŒºæ¶ˆæ¯åˆ†é…ï¼Œç„¶åå¤šä¸ªjobå¾®æœåŠ¡ï¼Œè¿™æ ·å°±ç»„æˆä¸€ä¸ªæ¶ˆè´¹è€…ç»„æ¥å¹¶è¡Œæ¶ˆè´¹kafkaã€‚ä½†æ˜¯ä¼šå¯¼è‡´ä¸èƒ½ä¿è¯æ¶ˆæ¯çš„æœ‰åºã€‚ä½†æ˜¯å¹‚ç­‰æ˜¯å¯ä»¥ä¿è¯çš„ï¼Œè€Œä¸€èˆ¬ä¸šåŠ¡ä¸­ï¼Œesåªè¦ä¿è¯å¹‚ç­‰å’Œæ¶ˆè´¹ä¸ä¼šæ¼å°±å¥½äº†ã€‚
    

## ä»esè·å–å…³ç³»

1. è¿æ¥es
    
    ```go
    func NewEsClient(cfg *conf.Elasticsearch) (*elasticsearch.TypedClient, error) {
    	c := elasticsearch.Config{
    		Addresses: cfg.Addresses,
    	}
    	return elasticsearch.NewTypedClient(c)
    }
    
    // åŠ å…¥index
    type Data struct {
    	// TODO wrapped database client
    	log *log.Helper
    	db  *gorm.DB
    	rdb *redis.Client
    
    	query   *query.Query
    	es      *elasticsearch.TypedClient
    	esIndex string
    
    	UserClient pbUser.UserServiceClient
    }
    
     esCfg *conf.Elasticsearch) 
     
     // æ³¨å…¥
    ```
    
2. è·å–
    
    ```go
    resq, err := r.data.es.Search().Index(r.data.esIndex).Query(
    		&types.Query{
    			Bool: &types.BoolQuery{
    				Must: []types.Query{
    					{
    						Term: map[string]types.TermQuery{
    							"user_id": {Value: userID},
    						},
    					},
    					{
    						Term: map[string]types.TermQuery{
    							"to_user_id": {
    								Value: toUserID},
    						},
    					},
    				},
    			},
    		}).Do(ctx)
    	if err != nil {
    		r.log.WithContext(ctx).Errorf("queryRelationExistInES es search error: %v", err)
    		return false, err
    	}
    	return resq.Hits.Total.Value > 0, nil
    ```
    

## ä»esæ¨¡ç³Šè·å–è§†é¢‘

1. è¿æ¥esï¼Œæ³¨å…¥
2. æ¨¡ç³Šæœç´¢

```go
func (r *videoRepo) GetVideoByTitle(ctx context.Context, title string) ([]*v1.Video, error) {
	r.log.WithContext(ctx).Infof("GetVideoByTitle: %v", title)
	r.log.WithContext(ctx).Debugf("esIndex: %s", r.data.esIndex)
	// 1. åœ¨esä¸­æ¨¡ç³ŠæŸ¥è¯¢
	res, err := r.data.es.Search().
		Index(r.data.esIndex).
		Query(
			&types.Query{
				Match: map[string]types.MatchQuery{
					"title": {Query: title},
				},
			},
		).
		Size(20).
		Do(ctx)
	if err != nil {
		r.log.WithContext(ctx).Errorf("get video err: %v", err)
		// 2ï¸âƒ£ å…œåº•ç”¨ SQL
		return r.getVideoByTitleFromDB(ctx, title)
	}
	if res == nil || res.Hits.Hits == nil || len(res.Hits.Hits) == 0 {
		r.log.WithContext(ctx).Warnf("ES no hits for title: %s, fallback to DB", title)
		return r.getVideoByTitleFromDB(ctx, title)
	}

	// 2. åœ¨sqlä¸­æ¨¡ç³ŠæŸ¥è¯¢å…œåº•

	videos := make([]*v1.Video, 0, len(res.Hits.Hits))
	for _, hit := range res.Hits.Hits {
		var video v1.Video
		if err := json.Unmarshal(hit.Source_, &video); err != nil {
			r.log.WithContext(ctx).Errorf("unmarshal video err: %v, source: %s", err, string(hit.Source_))
			continue
		}
		videos = append(videos, &video)
	}

	if len(videos) == 0 {
		return r.getVideoByTitleFromDB(ctx, title)
	}

	return videos, nil
}
```

# redisç¼“å­˜

1. ç¼“å­˜ç”¨æˆ·ä¿¡æ¯
2. è§†é¢‘æŒ‰åˆ†æ•°è·å–
    1. åˆ›å»ºè§†é¢‘åˆå§‹åŒ–è§†é¢‘åˆ†æ•°
    2. æ›´æ–°è¯„è®ºæ›´æ–°è§†é¢‘åˆ†æ•°
    3. æ›´æ–°ç‚¹èµæ›´æ–°è§†é¢‘åˆ†æ•°
    4. è·å–è§†é¢‘
        1. æŒ‰åˆ†æ•°æ’åºåˆ°ç¼“å­˜ä¸­è·å–è§†é¢‘id
        2. æ ¹æ®è§†é¢‘idåˆ°æ•°æ®åº“ä¸­æŸ¥æ‰¾è§†é¢‘ä¿¡æ¯
        3. æŒ‰åˆ†æ•°æ’åºè¿”å›è§†é¢‘

# prometheusç›‘æ§

1. é…ç½®
    
    ```go
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    
    scrape_configs:
      - job_name: "prometheus"
        static_configs:
          - targets: ["localhost:19091"]
    
      - job_name: "users-service"
        metrics_path: "/metrics"
        static_configs:
          - targets: ["host.docker.internal:8080"]
    
    docker volume create prometheus-data
    
    docker run -d --name prometheus `
      -p 19091:9090 `
      -v D:/my_program/goland/tiktok/pkg/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml `
      -v prometheus-data:/prometheus `
      prom/prometheus
    
    ```
    
2. æä¾›metric
    1. å®šä¹‰è¦ç›‘æ§çš„
        1. è¯·æ±‚æ¬¡æ•°
        2. è¯·æ±‚è€—æ—¶
        3. è¯·æ±‚é”™è¯¯ç‡
        4. dbæŸ¥è¯¢è€—æ—¶å’Œé”™è¯¯ç‡
        5. å†…å­˜å ç”¨ç‡
        6. cpu
        7. goroutine
        8. gc
        9. golang runtime
        10. kafka
        
        ç­‰
        
    2. å¼€å¯ä¸€ä¸ªç‹¬ç«‹çš„metricæœåŠ¡ï¼Œä¸ºprometheusæä¾›
        
        ```go
        func StartMetricsServer() {
        	http.Handle("/metrics", promhttp.Handler())
        	log.Println("Prometheus metrics exposed at :18081/metrics")
        	go func() {
        		if err := http.ListenAndServe(":18081", nil); err != nil {
        			log.Fatalf("Metrics server failed: %v", err)
        		}
        	}()
        }
        ```
        
    3. httpæ‰§è¡Œä¸­é—´ä»¶
        
        ```go
        
        // statusResponseWriter ç”¨æ¥è®°å½•è¿”å›çŠ¶æ€ç 
        type statusResponseWriter struct {
        	http.ResponseWriter
        	statusCode int
        }
        
        func (rw *statusResponseWriter) WriteHeader(code int) {
        	rw.statusCode = code
        	rw.ResponseWriter.WriteHeader(code)
        }
        
        // è¯·æ±‚æ•°é‡å’Œå¤„ç†æ—¶é—´
        // InstrumentHandler wraps your Kratos HTTP handler to collect Prometheus metrics, InstrumentHandler æ˜¯æ ¸å¿ƒä¸­é—´ä»¶
        func InstrumentHandler(next http.Handler) http.Handler {
        	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        		start := time.Now()
        		rw := &statusResponseWriter{ResponseWriter: w, statusCode: 200}
        
        		// æ‰§è¡Œä¸šåŠ¡é€»è¾‘
        		next.ServeHTTP(rw, r)
        		duration := time.Since(start).Seconds()
        
        		path := r.URL.Path
        		method := r.Method
        		status := http.StatusText(rw.statusCode)
        
        		RequestCount.WithLabelValues(path, method, status).Inc()
        		RequestDuration.WithLabelValues(path, method, status).Observe(duration)
        		if rw.statusCode >= 400 {
        			HTTPErrorCount.WithLabelValues(path, method, status).Inc()
        		}
        	})
        }
        ```
        
    4. åŠ å…¥åˆ°http
        
        ```go
        var opts = []http.ServerOption{
        		http.Middleware(
        			recovery.Recovery(),
        		),
        		http.Filter(metrics.InstrumentHandler),
        	}
        ```
        
    5. sqlçš„ç›‘æ§
        
        ```go
        done := ObserveDuration(metrics.DBQueryDuration, []string{"CheckUserExistByUsername"})
        	_, err := r.data.query.User.
        		WithContext(ctx).
        		Where(r.data.query.User.Username.Eq(userName)).
        		First()
        	done()
        	if err != nil {
        		if err == gorm.ErrRecordNotFound {
        			log.Debugf("user %s not exist", userName)
        			return false, nil
        		}
        		metrics.DBQueryErrorCount.WithLabelValues("CheckUserExistByUsername", err.Error()).Inc()
        		return false, err
        	}
        	
        	
        	// ObserveDuration Prometheus ç›‘æ§
        func ObserveDuration(histogram *prometheus.HistogramVec, labels []string) func() {
        	start := time.Now()
        	return func() {
        		histogram.WithLabelValues(labels...).Observe(time.Since(start).Seconds())
        	}
        }
        ```
        

## grafana

1. æ‹‰å–
    
    ```go
    docker run -d --name=grafana --add-host=host.docker.internal:host-gateway -p 3000:3000 grafana/grafana-oss
    ```
    
2. é…ç½®prometheusæ•°æ®æº
    
    Connectionsâ†’prometheus â†’Add new data sourceâ†’url(prometheus)â†’Save & Test
    
3. ä»ªè¡¨æ¿
    
    Dashboardsâ†’Create Dashboardâ†’Add visualization/import(json)â†’prometheus data source
    
4. è¾“å…¥è¡¨è¾¾å¼
    
    ```go
    user_service_requests_total,user_service_request_duration_seconds_bucket,go_goroutines
    go_memstats_alloc_bytes,process_cpu_seconds_total...
    ```
    
5. save

# å‹æµ‹

### wrk

```lua
wrk.method = "GET"
wrk.headers["Content-Type"] = "application/json"

paths = {
	 "/api/user/check?user_id=23359767250468865"
}

request = function()
  local path = paths[math.random(1, #paths)]
  return wrk.format(nil, path)
end

wrk -t4 -c100 -d30s -s multi_api.lua http://127.0.0.1:8080
```

ä¹Ÿå¯ä»¥ç”¨docker

```lua
docker run --rm williamyeh/wrk -t4 -c1000 -d30s http://host.docker.internal:8080/api/user?user_id=23359767250468865
```

# OpenTelemetry

1. ä¾èµ–é…ç½®
    
    ```go
    go get "go.opentelemetry.io/otel" \
      "go.opentelemetry.io/otel/exporters/stdout/stdoutmetric" \
      "go.opentelemetry.io/otel/exporters/stdout/stdouttrace" \
      "go.opentelemetry.io/otel/propagation" \
      "go.opentelemetry.io/otel/sdk/metric" \
      "go.opentelemetry.io/otel/sdk/resource" \
      "go.opentelemetry.io/otel/sdk/trace" \
      "go.opentelemetry.io/otel/semconv/v1.24.0" \
      "go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp"
    ```
    
2. åˆå§‹åŒ–
    1. å®šä¹‰èµ„æº`ç”¨äºæ ‡è¯†æœåŠ¡ä¿¡æ¯ï¼Œå¦‚ service.name, environment ç­‰`
        
        ```go
        res, err := resource.New(ctx,
        		resource.WithAttributes(
        			semconv.ServiceNameKey.String(serviceName), // è®¾ç½®æœåŠ¡åç§°
        			attribute.String("env", "dev"),             // å¯æ ¹æ®éœ€è¦è®¾ç½®ç¯å¢ƒ: dev/staging/prod
        		),
        	)
        ```
        
    2. åˆ›å»ºå‡ºå£ï¼Œç”¨äºé“¾è·¯è¿½è¸ªçš„jaegerå¯è§†åŒ–
        
        ```go
        exporter, err := otlptracegrpc.New(ctx,
        		otlptracegrpc.WithInsecure(),
        		otlptracegrpc.WithEndpoint("localhost:4317"), // Jaeger or Tempo OTLP gRPC endpoint
        		otlptracegrpc.WithDialOption(grpc.WithBlock()),
        	)
        ```
        
    3. æ‰¹é‡å‘é€ç»™jaeger
        
        ```go
        // åˆ›å»º BatchSpanProcessorï¼Œç”¨äºæ‰¹é‡å‘é€ Trace æ•°æ®ï¼ˆæé«˜æ€§èƒ½ï¼‰
        	bsp := sdktrace.NewBatchSpanProcessor(exporter)
        ```
        
    4. åˆ›å»ºTraceProvider
        
        ```go
        // åˆ›å»º TracerProviderï¼Œå¹¶è®¾ç½®èµ„æºä¿¡æ¯åŠ BatchSpanProcessor
        	tp := sdktrace.NewTracerProvider(
        		sdktrace.WithResource(res),
        		sdktrace.WithSpanProcessor(bsp),
        	)
        ```
        
    5. å…¨å±€è®¾ç½®
        
        ```go
        // è®¾ç½®å…¨å±€ TracerProviderï¼Œä¹‹åé€šè¿‡ otel.Tracer("") è·å–çš„ Tracer å³å¯ä½¿ç”¨
        	otel.SetTracerProvider(tp)
        ```
        
    6. ä¸Šä¸‹æ–‡ä¼ æ’­å™¨ï¼Œåˆ†å¸ƒå¼è·¨é“¾è·¯ä¼ é€’trace_id
        
        ```go
        // è®¾ç½®å…¨å±€ä¸Šä¸‹æ–‡ä¼ æ’­å™¨ï¼ŒTraceContext ç”¨äºåˆ†å¸ƒå¼é“¾è·¯è·¨æœåŠ¡ä¼ é€’ trace id
        	otel.SetTextMapPropagator(propagation.TraceContext{})
        ```
        
    7. å…³é—­
        
        ```go
        // è¿”å› shutdown å‡½æ•°ç”¨äºä¼˜é›…å…³é—­ï¼ˆKratos shutdown æ—¶è°ƒç”¨ï¼Œé¿å…ä¸¢å¤±æ•°æ®ï¼‰
        	return tp.Shutdown
        ```
        
3. é¡¹ç›®ä¸­ä½¿ç”¨
    1. åˆå§‹åŒ–
        
        ```go
        	// main.go
        	// ---------------OpenTelemetry--------------------
        	ctx := context.Background()
        	shutdown := otelsetup.InitTracerProvider(ctx, Name)
        	defer func() {
        		ctx, cancel := context.WithTimeout(ctx, time.Second*5)
        		defer cancel()
        		if err := shutdown(ctx); err != nil {
        			log.Fatalf("failed to shutdown tracer: %v", err)
        		}
        	}()
        	
        	
        ```
        
    2. grpcä¼ é€’
        
        ```go
        gogrpc "google.golang.org/grpc" 
        "go.opentelemetry.io/contrib/instrumentation/google.golang.org/grpc/otelgrpc"
        // æœåŠ¡ç«¯å£
        var opts = []grpc.ServerOption{
        		grpc.Middleware(
        			recovery.Recovery(),
        		),
        		grpc.Options(
        			gogrpc.StatsHandler(otelgrpc.NewServerHandler()),
        		),
        	}
        	
        // clentç«¯
        	connUser, err := grpc.DialInsecure(
        		ctx,
        		grpc.WithEndpoint(c.UserService.Endpoint),
        		grpc.WithDiscovery(rr),
        		grpc.WithOptions(gogrpc.WithStatsHandler(otelgrpc.NewClientHandler())),
        	)
        ```
        
    3. é€»è¾‘æ‰“ç‚¹
        1. çˆ¶span
            
            ```go
            // service
            // opentelemetry
            	ctx, span := tracing.StartSpan(ctx, "CommentService.CreateComment",
            		attribute.String("comment.video_id", strconv.FormatInt(in.VideoId, 10)),
            	)
            	defer span.End()
            ```
            
        2. å­spanï¼Œåœ¨grpcè°ƒç”¨ï¼Œsqlï¼Œredisç­‰è°ƒç”¨åœ°æ–¹æ‰“span
            
            ```go
            // 1.grpc
            ctx, span := tracing.StartSpan(ctx, "commentRepo.ParseToken",
            		attribute.String("token.length", fmt.Sprintf("%d", len(token))),
            	)
            	defer span.End()
            
            // 2. redis
            	keyVideoComment := fmt.Sprintf("video:comment:%d", req.VideoId)
            
            	ctxCache, spanCache := tracing.StartSpan(ctx, "Redis.CheckCache")
            	if err = c.checkVideoCommentInCache(ctxCache, keyVideoComment, req.VideoId); err != nil {
            		spanCache.RecordError(err)
            		spanCache.End()
            		return nil, err
            	}
            	spanCache.End()
            ```
            
        3. è¢«è°ƒç”¨æ–¹ä¹Ÿéœ€è¦æ‰“ç‚¹
        4. å°è£…tracing,sapn
            
            ```go
            // StartSpan starts and returns a span with context for more flexible usage.
            func StartSpan(ctx context.Context, spanName string, attrs ...attribute.KeyValue) (context.Context, trace.Span) {
            	tracer := otel.Tracer("app-tracer")
            	ctx, span := tracer.Start(ctx, spanName)
            	if len(attrs) > 0 {
            		span.SetAttributes(attrs...)
            	}
            	return ctx, span
            }
            
            // TraceFunc wraps a function with a span, reducing boilerplate.
            func TraceFunc(ctx context.Context, spanName string, fn func(ctx context.Context) error) error {
            	tracer := otel.Tracer("app-tracer")
            	ctx, span := tracer.Start(ctx, spanName)
            	defer span.End()
            	return fn(ctx)
            }
            ```
            

## jaeger

```go
docker run -d --name jaeger \
  -e COLLECTOR_OTLP_ENABLED=true \
  -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \
  -p 5775:5775/udp \
  -p 6831:6831/udp \
  -p 6832:6832/udp \
  -p 5778:5778 \
  -p 16686:16686 \
  -p 14268:14268 \
  -p 14250:14250 \
  -p 4317:4317 \            # å¯ç”¨ gRPC
  -p 4318:4318 \            # å¯é€‰ï¼šHTTP
  -p 9411:9411 \
  jaegertracing/all-in-one:latest
```

## é…ç½®åˆ°granan

# zapæ—¥å¿—

1. é…ç½®
    
    ```go
    message Log {
      string level = 1;
      string path = 2;
      int32 max_size = 3;
      int32 max_backups = 4;
      int32 max_age = 5;
      bool compress = 6;
      bool console = 7;
    }
    
    log:
      level: debug
      path: ../logs/app.log
      max_size: 100
      max_backups: 5
      max_age: 3
      compress: true
      console: true
    ```
    
2. å°è£…
    
    ```go
    // zapLogger å®ç° Kratos log.Logger æ¥å£ï¼Œå°è£… zap.SugaredLogger
    // ç”¨äºåœ¨ Kratos ä¸­æ— ä¾µå…¥æ›¿æ¢æ—¥å¿—ï¼Œæ”¯æŒæ§åˆ¶å°æ‰“å°ä¸æ–‡ä»¶è½ç›˜
    // é€šè¿‡ zapcoreã€lumberjack å®ç°æŒ‰å¤§å°åˆ‡å‰²ã€ä¿ç•™å†å²ã€å‹ç¼©å½’æ¡£
    type zapLogger struct {
    	log *zap.SugaredLogger
    }
    
    // Log å®ç° Kratos log.Logger æ¥å£çš„æ–¹æ³•ï¼Œå°† Kratos Level æ˜ å°„åˆ° zap æ–¹æ³•
    func (l *zapLogger) Log(level log.Level, keyvals ...interface{}) error {
    	switch level {
    	case log.LevelDebug:
    		l.log.Debugw("", keyvals...)
    	case log.LevelInfo:
    		l.log.Infow("", keyvals...)
    	case log.LevelWarn:
    		l.log.Warnw("", keyvals...)
    	case log.LevelError:
    		l.log.Errorw("", keyvals...)
    	default:
    		l.log.Infow("", keyvals...)
    	}
    	return nil
    }
    
    type LogConfig struct {
    	Level      string `yaml:"level"`
    	Path       string `yaml:"path"`
    	MaxSize    int    `yaml:"max_size"`
    	MaxBackups int    `yaml:"max_backups"`
    	MaxAge     int    `yaml:"max_age"`
    	Compress   bool   `yaml:"compress"`
    	Console    bool   `yaml:"console"`
    }
    
    // NewZapLogger åˆ›å»ºå¯ç›´æ¥ç”¨äº Kratos log.With çš„ zapLogger å®ä¾‹
    // è½ç›˜åˆ° logs/app.logï¼ˆJSONï¼‰ï¼Œæ§åˆ¶å°é»˜è®¤ io.Discardï¼Œå¦‚éœ€æ‰“å°æ›¿æ¢ä¸º os.Stdout
    func NewZapLogger(cfg LogConfig) log.Logger {
    	encoderConfig := zap.NewProductionEncoderConfig()
    	encoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder
    
    	fileWriter := zapcore.AddSync(&lumberjack.Logger{
    		Filename:   cfg.Path,
    		MaxSize:    cfg.MaxSize,    // å•æ–‡ä»¶æœ€å¤§ 100MB
    		MaxBackups: cfg.MaxBackups, // æœ€å¤šä¿ç•™ 10 ä¸ªå†å²æ–‡ä»¶
    		MaxAge:     cfg.MaxAge,     // æ–‡ä»¶æœ€å¤§ä¿å­˜å¤©æ•°
    		Compress:   cfg.Compress,   // æ˜¯å¦å‹ç¼©å½’æ¡£
    	})
    
    	var consoleWriter zapcore.WriteSyncer = zapcore.AddSync(io.Discard)
    	if cfg.Console {
    		consoleWriter = zapcore.AddSync(os.Stdout)
    	}
    
    	level := zap.InfoLevel
    	switch strings.ToLower(cfg.Level) {
    	case "debug":
    		level = zap.DebugLevel
    	case "info":
    		level = zap.InfoLevel
    	case "warn", "warning":
    		level = zap.WarnLevel
    	case "error":
    		level = zap.ErrorLevel
    	}
    
    	core := zapcore.NewCore(
    		zapcore.NewJSONEncoder(encoderConfig),
    		zapcore.NewMultiWriteSyncer(fileWriter, consoleWriter),
    		level,
    	)
    
    	logger := zap.New(core, zap.AddCaller(), zap.AddCallerSkip(1)).Sugar()
    	return &zapLogger{log: logger}
    }
    
    var _ log.Logger = (*zapLogger)(nil)
    
    ```
    
3. æ³¨å…¥
    
    ```go
    	var logCfg pkg.LogConfig
    	if err := c.Scan(&logCfg); err != nil {
    		panic(err)
    	}
    	logger := log.With(pkg.NewZapLogger(logCfg),
    		//"ts", log.DefaultTimestamp,
    		//"caller", log.DefaultCaller,
    		"service.id", id,
    		"service.name", Name,
    		"service.version", Version,
    		"trace.id", tracing.TraceID(),
    		"span.id", tracing.SpanID(),
    	)
    
    ```
    

# é™æµï¼Œç†”æ–­

1. é™æµï¼ˆä»¤ç‰Œæ¡¶ï¼‰
    
    ```go
    import (
    	"context"
    	"errors"
    	"github.com/go-kratos/kratos/v2/middleware"
    	"golang.org/x/time/rate"
    )
    
    // RateLimitMiddleware è¿”å›ä¸€ä¸ªé™æµä¸­é—´ä»¶ï¼ŒåŸºäºä»¤ç‰Œæ¡¶ç®—æ³•ã€‚
    // qps æ˜¯å…è®¸çš„è¯·æ±‚é€Ÿç‡ï¼Œburst æ˜¯å…è®¸çš„çªå‘å®¹é‡ã€‚
    func RateLimitMiddleware(qps float64, burst int) middleware.Middleware {
    	limiter := rate.NewLimiter(rate.Limit(qps), burst)
    
    	return func(next middleware.Handler) middleware.Handler {
    		return func(ctx context.Context, req interface{}) (interface{}, error) {
    			// Allow å…è®¸ç«‹å³è·å–ä¸€ä¸ªä»¤ç‰Œï¼Œå¦‚æœè·å–ä¸åˆ°ç›´æ¥è¿”å›é™æµé”™è¯¯ã€‚
    			if !limiter.Allow() {
    				return nil, errors.New("too many requests - rate limit exceeded")
    			}
    			return next(ctx, req)
    		}
    	}
    }
    
    ```
    
2. ç†”æ–­
    
    ```go
    import (
    	"github.com/sony/gobreaker"
    	"time"
    )
    
    // CircuitBreaker åŒ…è£…äº† sony/gobreaker.CircuitBreakerï¼Œæ–¹ä¾¿å¤ç”¨ã€‚
    type CircuitBreaker struct {
    	cb *gobreaker.CircuitBreaker
    }
    
    // NewCircuitBreaker åˆ›å»ºä¸€ä¸ªæ–°çš„ç†”æ–­å™¨ï¼Œname æ ‡è¯†ç†”æ–­å™¨åç§°ã€‚
    func NewCircuitBreaker(name string) *CircuitBreaker {
    	settings := gobreaker.Settings{
    		Name:        name,
    		MaxRequests: 5,                // åŠå¼€çŠ¶æ€æœ€å¤§å…è®¸è¯·æ±‚æ•°
    		Interval:    60 * time.Second, // ç»Ÿè®¡çª—å£å‘¨æœŸï¼Œè®¡æ•°æ¸…é›¶
    		Timeout:     30 * time.Second, // ç†”æ–­æ‰“å¼€åå°è¯•æ¢å¤æ—¶é—´
    		ReadyToTrip: func(counts gobreaker.Counts) bool {
    			// å¤±è´¥ç‡è¶…è¿‡60%ï¼Œä¸”è¯·æ±‚æ•°è‡³å°‘10ä¸ªæ—¶æ‰“å¼€ç†”æ–­
    			failureRatio := float64(counts.TotalFailures) / float64(counts.Requests)
    			return counts.Requests >= 10 && failureRatio >= 0.6
    		},
    	}
    	return &CircuitBreaker{
    		cb: gobreaker.NewCircuitBreaker(settings),
    	}
    }
    
    // Execute æ‰§è¡Œå‡½æ•°ï¼Œå¦‚æœç†”æ–­å™¨æ‰“å¼€åˆ™ç›´æ¥è¿”å›é”™è¯¯ã€‚
    // å‡½æ•°å†…éƒ¨éœ€è¦è¿”å› (interface{}, error)ï¼Œ
    func (c *CircuitBreaker) Execute(req func() (interface{}, error)) (interface{}, error) {
    	return c.cb.Execute(req)
    }
    
    ```
    

<aside>
ğŸ’¡

é™æµå°±æ˜¯æ§åˆ¶è®¿é—®æœåŠ¡çš„è¯·æ±‚é€Ÿç‡ï¼Œé¿å…ç¬æ—¶æµé‡è¿‡å¤§å‹å®æœåŠ¡ã€‚

**ç†”æ–­**çš„ä½œç”¨ç¨å¾®ä¸åŒï¼Œå®ƒæ˜¯ä¿æŠ¤æœåŠ¡åœ¨å‡ºç°æ•…éšœæ—¶â€œå¿«é€Ÿå¤±è´¥â€å’Œâ€œè‡ªåŠ¨æ¢å¤â€çš„æœºåˆ¶ï¼Œé˜²æ­¢æ•…éšœæ‰©å¤§ï¼Œé¿å…é›ªå´©æ•ˆåº”ã€‚å…·ä½“æ¥è¯´ï¼š

- å½“è°ƒç”¨æŸä¸ªä¸‹æ¸¸æœåŠ¡æ—¶ï¼Œå¦‚æœå®ƒè¿ç»­å‡ºç°å¤±è´¥ï¼ˆæ¯”å¦‚å“åº”è¶…æ—¶ã€é”™è¯¯ç‡è¿‡é«˜ç­‰ï¼‰ï¼Œç†”æ–­å™¨å°±ä¼šâ€œæ‰“å¼€â€ã€‚
- æ‰“å¼€åï¼Œåç»­è°ƒç”¨ä¸ä¼šå†å‘åˆ°è¿™ä¸ªæ•…éšœæœåŠ¡ï¼Œè€Œæ˜¯ç«‹åˆ»è¿”å›é”™è¯¯ï¼Œå¿«é€Ÿå¤±è´¥ï¼ŒèŠ‚çœèµ„æºã€‚
- ç»è¿‡ä¸€æ®µæ—¶é—´ï¼ˆç†”æ–­å™¨çš„é‡è¯•é—´éš”ï¼‰ï¼Œç†”æ–­å™¨ä¼šè¿›å…¥â€œåŠå¼€â€çŠ¶æ€ï¼Œå…è®¸å°‘é‡è¯·æ±‚å°è¯•è°ƒç”¨æœåŠ¡ï¼Œçœ‹æœåŠ¡æ˜¯å¦æ¢å¤ã€‚
- å¦‚æœæ¢å¤æ­£å¸¸ï¼Œç†”æ–­å™¨â€œå…³é—­â€ï¼Œæ¢å¤æ­£å¸¸è°ƒç”¨ï¼›å¦åˆ™ç»§ç»­ä¿æŒâ€œæ‰“å¼€â€ï¼Œæ‹’ç»è¯·æ±‚ã€‚

è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼š

- é¿å…å®¢æˆ·ç«¯æ— é™åˆ¶ç­‰å¾…ä¸€ä¸ªå·²ç»ä¸å¯ç”¨çš„æœåŠ¡ï¼Œæé«˜ç³»ç»Ÿå“åº”é€Ÿåº¦å’Œç¨³å®šæ€§ã€‚
- ç»™ä¸‹æ¸¸æœåŠ¡â€œå–˜æ¯â€æ—¶é—´ï¼Œå‡å°‘è¿é”æ•…éšœæ‰©æ•£ã€‚
- æ•´ä½“æå‡å¾®æœåŠ¡ç³»ç»Ÿçš„å¥å£®æ€§å’Œå®¹é”™èƒ½åŠ›ã€‚
</aside>

| åŠŸèƒ½ | é™æµ | ç†”æ–­ |
| --- | --- | --- |
| ç›®çš„ | æ§åˆ¶è®¿é—®é¢‘ç‡ï¼Œé˜²æ­¢æµé‡æš´æ¶¨ | ä¿æŠ¤è°ƒç”¨æ–¹ï¼Œå¿«é€Ÿå¤±è´¥å’Œæ¢å¤ |
| ä½œç”¨å¯¹è±¡ | æœåŠ¡å…¥å£è¯·æ±‚ | ä¸‹æ¸¸æœåŠ¡è°ƒç”¨ |
| è§¦å‘æ¡ä»¶ | è¯·æ±‚é€Ÿç‡è¶…è¿‡è®¾å®šé˜ˆå€¼ | ä¸‹æ¸¸æœåŠ¡è¿ç»­å¤±è´¥ç‡è¿‡é«˜ |
| å¤„ç†æ–¹å¼ | æ‹’ç»è¶…å‡ºé€Ÿç‡çš„è¯·æ±‚ | æ‹’ç»è°ƒç”¨æ•…éšœæœåŠ¡ï¼Œå¿«é€Ÿè¿”å›é”™è¯¯ |
1. ä½¿ç”¨

```go
// åˆ›å»ºé™æµä¸­é—´ä»¶ï¼Œé™åˆ¶å…¨å±€å…¥å£è¯·æ±‚
var RateLimitMw = middleware.RateLimitMiddleware(1000, 1888) // 100 QPSï¼Œçªå‘200

var opts = []http.ServerOption{
		http.Middleware(
			recovery.Recovery(),
			RateLimitMw,
		),
	}

	grpc.Middleware(
			recovery.Recovery(),
			RateLimitMw,
		),
		

```

1. é€»è¾‘ä¸­ä½¿ç”¨
    
    ```go
    var (
    	// å…¨å±€é™æµå™¨ï¼Œ10 QPSï¼Œburst 20
    	commentRateLimiter = middleware.RateLimitMiddleware(10, 20)
    
    	// comment -> user æœåŠ¡è°ƒç”¨ç†”æ–­å™¨
    	userParseTokenCB = middleware.NewCircuitBreaker("user-parse-token")
    )
    
    func (c *commentRepo) ParseToken(ctx context.Context, token, refreshToken string) (int64, error) {
    
    	exec := func(ctx context.Context) (interface{}, error) {
    		ctx, span := tracing.StartSpan(ctx, "commentRepo.ParseToken",
    			attribute.String("token.length", fmt.Sprintf("%d", len(token))),
    		)
    		defer span.End()
    
    		return userParseTokenCB.Execute(func() (interface{}, error) {
    			return c.data.UserClient.ParseToken(ctx, &pbUser.ParseTokenRequest{
    				Token:        token,
    				RefreshToken: refreshToken,
    			})
    		})
    	}
    
    	result, err := commentRateLimiter(func(ctx context.Context, req interface{}) (interface{}, error) {
    		return exec(ctx)
    	})(ctx, nil)
    
    	if err != nil {
    		return 0, err
    	}
    
    	resp, ok := result.(*pbUser.ParseTokenReply)
    	if !ok || resp == nil {
    		return 0, errors.New("failed to parse token")
    	}
    
    	return resp.UserId, nil
    }
    
    ```
    

# git

1. æ¨é€
    1. git checkout -b feature/xxx
    2. git add xxxxx
    3. git status
    4.  git commit -m â€œxxxxâ€
    5. git push origin feature/xxx
2. åˆå¹¶
    1. git checkout develop
    2. git branch â€”> develop
    3. git push origin develop
    4. git merge feature/xxx
    5. åˆå¹¶main

# Docker

> docker build -t youngking666/xxxx-service:latest .

>docker run -d --name xxxx-service-test -p 8081:8081  -p 908x:908x youngking666/xxxx-service:latest

> docker push youngking666/xxxx-service:latest

è¿™é‡Œæ–°å»ºä¸€ä¸ªç½‘ç»œï¼Œå¹¶ä¸”å°†å®¹å™¨æ”¾å…¥åˆ°ä¸€ä¸ªç½‘ç»œä¸­

docker network create tiktok-network

dokcer network connect tiktok-network youngking666/xxxx-service:latest

docker network inspect  tiktok-network

è¿™æ ·åœ¨é¡¹ç›®ä¸­çš„é…ç½®æ–‡ä»¶çš„å„ä¸ªå®¹å™¨çš„åœ°å€å¯ä»¥ç›´æ¥æ”¹ä¸º

contanier-name:port

# consul

1. æœåŠ¡æ³¨å†Œ
    
    ```go
    func NewRegistry(cfg *conf.Registry) registry.Registrar {
    	c := api.DefaultConfig()
    	c.Address = cfg.Consul.Addr
    	c.Scheme = cfg.Consul.Scheme
    	client, err := api.NewClient(c)
    	if err != nil {
    		panic(err)
    	}
    
    	reg := consul.New(client, consul.WithHealthCheck(true))
    	return reg
    }
    
    func newApp(logger log.Logger, gs *grpc.Server, hs *http.Server, reg registry.Registrar) *kratos.App {
    	return kratos.New(
    		kratos.ID(id),
    		kratos.Name(Name),
    		kratos.Version(Version),
    		kratos.Metadata(map[string]string{}),
    		kratos.Logger(logger),
    		kratos.Server(
    			gs,
    			hs,
    		),
    		kratos.Registrar(reg),
    	)
    }
    ```
    
2. æœåŠ¡å‘ç°
    
    ```go
    func NewDiscover(cfg *conf.Registry) registry.Discovery {
    	// new consul client
    	c := api.DefaultConfig()
    	c.Address = cfg.Consul.Addr
    	c.Scheme = cfg.Consul.Scheme
    	client, err := api.NewClient(c)
    	if err != nil {
    		panic(err)
    	}
    	// new dis with consul client
    	reg := consul.New(client)
    	return reg
    }
    
    func NewUserServiceClient(c *conf.Data, rr registry.Discovery) pbUser.UserServiceClient {
    	conn, err := grpc.DialInsecure(
    		context.Background(),
    		grpc.WithEndpoint(c.UserService.Endpoint),
    		grpc.WithDiscovery(rr),
    		grpc.WithOptions(gogrpc.WithStatsHandler(otelgrpc.NewClientHandler())),
    	)
    	if err != nil {
    		panic(err)
    	}
    	return pbUser.NewUserServiceClient(conn)
    }
    ```
    

# docker-compose

1. mysql æ•°æ®é…ç½®è¿ç§»
    1. æ•°æ®åº“
        
        ```go
        mysqldump -u root -p --databases tiktok > tiktok_backup.sql
        
        // æ‰¾åˆ°tiktok_backup.sqlå¹¶ä¿å­˜
        
        // å¤åˆ¶åˆ°å®¹å™¨ä¸­
        // docker cp D:\my_program\goland\tiktok\tiktok_backup.sql new_mysql_container:/tiktok_backup.sql
        
        // æ‰§è¡Œ
        // docker exec -it new_mysql_container bash
        // mysql -u root -p < /tiktok_backup.sql
        æˆ‘è¿™é‡Œæ²¡æœ‰ç”¨è¿™ç§æ–¹å¼ï¼Œç”¨çš„æ˜¯åœ¨docker-composeä¸­ç›´æ¥å¯¼å…¥ã€‚
        é‡Œé¢æœ‰å‘ï¼ï¼ï¼
        å¯¼å‡ºçš„ tiktok_backup.sql ä¸­æœ‰
        1. create use è¿™é‡Œå¯èƒ½ä¼šå¯¼è‡´å‡ºé”™ï¼Œå¦‚æœä½ å·²ç»æœ‰æœ‰è¿™ä¸ªæ•°æ®åº“äº†ï¼Œå°±åˆ é™¤ 
        2. æ¢è¡Œç¬¦çš„é—®é¢˜ï¼ï¼ï¼
        		**dos2unix ./mysql/tiktok_backup.sql**
        ä¸€å®šè¦ä¿®æ”¹æ¢è¡Œç¬¦ï¼Œå¯èƒ½æ˜¯æˆ‘æ˜¯windowsçš„åŸå› ï¼Œæœ€å¼€å§‹æ²¡æœ‰æ¢è¡Œç¬¦ï¼Œä¸€ç›´å‡ºé”™
        3. æ–‡ä»¶æƒé™çš„é—®é¢˜ï¼Œä¿®æ”¹ä¸º644
        ```
        
    2. é…ç½®æ–‡ä»¶
        
        ```go
        mysql --help | grep my.cnf
        
                              order of preference, my.cnf, $MYSQL_TCP_PORT,
        /etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf 
        
        // æ‰¾åˆ°/etc/my.cnfä¿å­˜ï¼Œè¿™ä¸ªæ˜¯æˆ‘ä¹‹å‰ä¿®æ”¹çš„ã€‚è®°å¾—åŠ æƒé™
        
        // æŒ‚è½½
            volumes:
              - ./my.cnf:/etc/my.cnf
              - mysql_data:/var/lib/mysql
        ```
        
2. canalé…ç½®æ–‡ä»¶
    
    ```go
    è¿™é‡Œæœ‰å‡ ä¸ªä¼‘è¦ä¿®æ”¹çš„ï¼Œå‘ï¼ï¼ï¼
    1. meta.dat åˆ é™¤ï¼Œä¸ç„¶ä¼šæŠ¥é”™çš„ã€‚
    2. ä¿®æ”¹ ./canal-conf/canal.properties å’Œinstanceä¸­é…ç½®ï¼Œdocker.host.internal æ”¹ä¸ºmysql å’Œkafka
    2.1 é…ç½®æ–‡ä»¶ä¸­çš„29092ä¹Ÿå¯ä»¥ä¸è¦äº†ï¼Œè¿™é‡Œéœ€è¦ä¿®æ”¹canal.properties å“ªé‡Œçš„mysqlä¹Ÿæ”¹ä¸º19092
    3. å…ˆè¯•è¯•ä¸Šé¢åˆ é™¤äº†æ˜¯å¦èƒ½è¡Œï¼Œå¦‚æœä¸èƒ½è¡Œï¼Œå°±æ¥ä¸‹æ¥
    3. ./canal-conf/canal.properties
    		canal.instance.parser=com.alibaba.otter.canal.parse.inbound.mysql.MysqlEventParser
    ```
    
3. å¯åŠ¨æˆ–åˆ é™¤
    
    ```go
    docker-compose down -v --remove-orphans
    
    	
    docker-compose build --no-cache  # å¯é€‰ï¼Œå¦‚æœä½ æƒ³å¼ºåˆ¶é‡æ–°æ„å»ºé•œåƒ
    docker-compose up -d
    ```
    

# k8s

```go
[root@master ~]# kubectl cluster-info
Kubernetes master is running at https://192.168.198.100:6443
KubeDNS is running at https://192.168.198.100:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.

[root@master ~]# kubectl get nodes
NAME     STATUS   ROLES    AGE   VERSION
master   Ready    master   50d   v1.17.4
node1    Ready    <none>   50d   v1.17.4
node2    Ready    <none>   50d   v1.17.4

[root@master ~]# kubectl get storageclass
No resources found in default namespace.

[root@master ~]# kubectl get storageclass -n tiktok
No resources found in tiktok namespace.

[root@master ~]# vim local-storageclass.yaml
[root@master ~]# kubectl apply -f local-storageclass.yaml

		apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer

storageclass.storage.k8s.io/local-storage created
[root@master ~]# kubectl get storageclass -n tiktok
NAME            PROVISIONER                    RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
local-storage   kubernetes.io/no-provisioner   Delete          WaitForFirstConsumer   false                  16s
[root@master ~]#

[root@master ~]# kubectl get storageclass -n tiktok
NAME            PROVISIONER                    RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
local-storage   kubernetes.io/no-provisioner   Delete          WaitForFirstConsumer   false                  16s

[root@master ~]# vim pv.yaml
	apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-mysql
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    path: /data/mysql
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node1
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-redis
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    path: /data/redis
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node1
		
[root@master ~]# kubectl apply -f pv.yaml
persistentvolume/pv-mysql created
persistentvolume/pv-redis created
[root@master ~]# kubectl get storageclass
NAME            PROVISIONER                    RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
local-storage   kubernetes.io/no-provisioner   Delete          WaitForFirstConsumer   false                  5m58s
[root@master ~]# kubectl get pv
NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS    REASON   AGE
pv-mysql   10Gi       RWO            Retain           Available           local-storage            16s
pv-redis   10Gi       RWO            Retain           Available           local-storage            16s
[root@master ~]# ^C
[root@master ~]# mkdir tiktok
[root@master ~]# vim pv.yaml 
	apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-kafka
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    path: /data/kafka
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node1
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-minio
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    path: /data/minio
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node1
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-es
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    path: /data/es
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node1
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-prometheus
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    path: /data/prometheus
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node1
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-grafana
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    path: /data/grafana
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node1
ssh node1
[root@node1 data]# mkdir -p /data/kafka /data/minio /data/es /data/prometheus /data/grafana
[root@node1 data]# chmod 777 /data/kafka /data/minio /data/es /data/prometheus /data/grafana

[root@master ~]# kubectl get pv
NAME            CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS    REASON   AGE
pv-es           1Gi        RWO            Retain           Available           local-storage            16h
pv-grafana      1Gi        RWO            Retain           Available           local-storage            16h
pv-kafka        1Gi        RWO            Retain           Available           local-storage            16h
pv-minio        1Gi        RWO            Retain           Available           local-storage            16h
pv-mysql        2Gi        RWO            Retain           Available           local-storage            16h
pv-prometheus   1Gi        RWO            Retain           Available           local-storage            16h
pv-redis        10Gi       RWO            Retain           Available           local-storage            16h

#####################################
ä¸Šä¼ é…ç½®æ–‡ä»¶ï¼Œè½¬æ¢é…ç½®æ–‡ä»¶
# å®‰è£… dos2unix
yum install dos2unix  # CentOS
# æˆ–
apt-get update && apt-get install dos2unix  # Ubuntu

# è½¬æ¢æ–‡ä»¶
cd /root/config
dos2unix ./mysql/my.cnf ./mysql/init.sql ./mysql/tiktok_backup.sql ./prometheus.yml
find ./canal-conf -type f -exec dos2unix {} \;

# éªŒè¯
file ./mysql/my.cnf
cat -v ./mysql/my.cnf | head -n 5
###########################################

kubectl create configmap mysql-config \
  --from-file=./mysql/my.cnf \
  --from-file=./mysql/init.sql \
  --from-file=./mysql/tiktok_backup.sql \
  -n tiktok

kubectl create configmap canal-config \
  --from-file=./canal-conf \
  -n tiktok

kubectl create configmap prometheus-config \
  --from-file=./prometheus.yml \
  -n tiktok
  
 kubectl create secret generic mysql-secret \
  --from-literal=root-password=root \
  --from-literal=database=root\
  -n tiktok

kubectl create secret generic canal-secret \
  --from-literal=canal-username=ysh \
  --from-literal=canal-password=ysh \
  -n tiktok

kubectl create secret generic minio-secret \
  --from-literal=access-key=admin \
  --from-literal=secret-key=admin123 \
  -n tiktok

kubectl create secret generic grafana-secret \
  --from-literal=admin-password=admin \
  -n tiktok
  
  ä¸‹è½½kompose
  curl -L https://github.com/kubernetes/kompose/releases/download/v1.22.0/kompose-linux-amd64 -o kompose
  ä¹Ÿå¯ä»¥ç›´æ¥ä¸‹è½½åˆ°æœ¬åœ°åä¸Šä¼ åˆ°æœåŠ¡å™¨
  
	chmod +x kompose-linux-amd64
	sudo mv kompose-linux-amd64 /usr/local/bin/kompose
	kompose version
	
[root@master config]# kompose version
1.22.0 (955b78124)
[root@master config]# file /usr/local/bin/kompose
/usr/local/bin/kompose: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, stripped
[root@master config]# /usr/local/bin/kompose version
1.22.0 (955b78124)

ä¿®æ”¹docker-compose.yamlï¼Œå› ä¸ºä¸æ”¯æŒnetworkç­‰ï¼Œéœ€è¦ä¿®æ”¹
[root@master config]# mkdir kubernetes-manifests
[root@master config]# kompose convert -o kubernetes-manifests/
[root@master config]# ls kubernetes-manifests/

ä¿®æ”¹ç”Ÿäº§çš„é…ç½®æ–‡ä»¶çš„development, serviceï¼Œ data-pvc
[root@master kubernetes-manifests]# vim mysql-deployment.yaml
[root@master kubernetes-manifests]# vim mysql-service.yaml
[root@master kubernetes-manifests]# vim mysql-data-persistentvolumeclaim.yaml

// åˆ›å»º
[root@master kubernetes-manifests]# kubectl apply -f mysql-deployment.yaml -f mysql-service.yaml -f mysql-data-persistentvolumeclaim.yaml -             n tiktok

// æŸ¥çœ‹
[root@master kubernetes-manifests]# kubectl get pods -n tiktok -o wide
[root@master kubernetes-manifests]# kubectl get svc -n tiktok
[root@master kubernetes-manifests]# kubectl get pvc -n tiktok

```

## 1. namespace

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: tiktok
```

## 2. mysql

1. configmap
    
    ```go
    # æ³¨æ„è·¯å¾„è¦å‡†ç¡®
    kubectl create configmap mysql-config \
      --from-file=my.cnf=./mysql/my.cnf \
      -n tiktok
    
    kubectl create configmap mysql-init-sql \
      --from-file=1_init.sql=./mysql/init.sql \
      --from-file=2_tiktok_backup.sql=./mysql/tiktok_backup.sql \
      -n tiktok
    
    ```
    
2. pv
    
    ```yaml
    # mysql-pv.yaml
    apiVersion: v1
    kind: PersistentVolume
    metadata:
      name: mysql-pv
    spec:
      capacity:
        storage: 10Gi
      accessModes:
        - ReadWriteOnce
      persistentVolumeReclaimPolicy: Retain
      hostPath:
        path: /data/mysql
      nodeAffinity:
        required:
          nodeSelectorTerms:
            - matchExpressions:
                - key: kubernetes.io/hostname
                  operator: In
                  values:
                    - node2
    
    ssh node2
    sudo mkdir -p /data/mysql
    sudo chown -R 999:999 /data/mysql   # 999 æ˜¯ mysql å®¹å™¨ç”¨æˆ·ï¼ˆmysql:8 é»˜è®¤ï¼‰
    ```
    
3. pvc
    
    ```yaml
    
    # mysql-pvc.yaml
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: mysql-pvc
      namespace: tiktok
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      volumeName: mysql-pv
    
    ```
    
4. deployment
    
    ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: mysql
      namespace: tiktok
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: mysql
      template:
        metadata:
          labels:
            app: mysql
        spec:
          nodeSelector:
            kubernetes.io/hostname: node2
          containers:
            - name: mysql
              image: mysql:8.0.36
              ports:
                - containerPort: 3306
              env:
                - name: MYSQL_ROOT_PASSWORD
                  value: root
                - name: MYSQL_DATABASE
                  value: tiktok
                - name: TZ
                  value: Asia/Shanghai
              volumeMounts:
                - name: config
                  mountPath: /etc/my.cnf
                  subPath: my.cnf
                - name: init-sql
                  mountPath: /docker-entrypoint-initdb.d/1_init.sql
                  subPath: 1_init.sql
                - name: init-sql
                  mountPath: /docker-entrypoint-initdb.d/2_tiktok_backup.sql
                  subPath: 2_tiktok_backup.sql
                - name: mysql-data
                  mountPath: /var/lib/mysql
          volumes:
            - name: config
              configMap:
                name: mysql-config
            - name: init-sql
              configMap:
                name: mysql-init-sql
            - name: mysql-data
              persistentVolumeClaim:
                claimName: mysql-pvc
    
    ```
    
5. service
    
    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: mysql
      namespace: tiktok
    spec:
      type: NodePort
      selector:
        app: mysql
      ports:
        - port: 3306
          targetPort: 3306
          nodePort: 30306  # 30000~32767 èŒƒå›´å†…
    
    ```
    
6. éƒ¨ç½²
    
    ```yaml
    # 1. åˆ›å»º Namespace
    kubectl apply -f k8s/mysql/namespace.yaml
    
    # 2. åˆ›å»º PV
    kubectl apply -f k8s/mysql/mysql-pv.yaml
    
    # 3. åˆ›å»º PVCï¼ˆç»‘å®šåˆšæ‰çš„ PVï¼‰
    kubectl apply -f k8s/mysql/mysql-pvc.yaml
    
    # 4. åˆ›å»º ConfigMapï¼ˆä»æ–‡ä»¶ï¼‰
    kubectl create configmap mysql-config \
      --from-file=my.cnf=k8s/mysql/my.cnf \
      -n tiktok
    
    kubectl create configmap mysql-init-sql \
      --from-file=1_init.sql=k8s/mysql/init.sql \
      --from-file=2_tiktok_backup.sql=k8s/mysql/tiktok_backup.sql \
      -n tiktok
    
    # 5. éƒ¨ç½² Deploymentï¼ˆä½¿ç”¨ PVCã€ConfigMapã€å›ºå®š node2ï¼‰
    kubectl apply -f k8s/mysql/deployment.yaml
    
    # 6. åˆ›å»º Serviceï¼ˆæš´éœ² NodePort å¤–éƒ¨å¯è®¿é—®ï¼‰
    kubectl apply -f k8s/mysql/service.yaml
    ```
    
7. æµ‹è¯•
    
    ```yaml
    kubectl get pods -n tiktok -o wide
    kubectl get svc -n tiktok
    
    kubectl get pv
    kubectl get pvc -n tiktok
    
    kubectl exec -it mysql-xxxxxxxxxx -n tiktok -- bash
    ```
    

## 3. redis

1. redis-pv.yaml
    
    ```yaml
    apiVersion: v1
    kind: PersistentVolume           # å®šä¹‰çš„æ˜¯æŒä¹…å·
    metadata:
      name: redis-pv                 # PV çš„åç§°ï¼ŒPVC ä¼šé€šè¿‡è¿™ä¸ªåç§°æ¥ç»‘å®šå®ƒ
    spec:
      capacity:
        storage: 1Gi                 # å­˜å‚¨å®¹é‡ï¼Œè¿™é‡Œæ˜¯ 1 GiB
      accessModes:
        - ReadWriteOnce             # åªå…è®¸ä¸€ä¸ªèŠ‚ç‚¹ä»¥è¯»å†™æ¨¡å¼æŒ‚è½½è¿™ä¸ªå·
      persistentVolumeReclaimPolicy: Retain  # åˆ é™¤ PVC åï¼Œä¿ç•™ PV ä¸­çš„æ•°æ®
      hostPath:
        path: /data/redis            # å®é™…åœ¨ node2 ä¸Šçš„æ•°æ®è·¯å¾„
      nodeAffinity:                  # é™åˆ¶è¿™ä¸ªå·åªèƒ½è¢« node2 èŠ‚ç‚¹ä½¿ç”¨
        required:
          nodeSelectorTerms:
            - matchExpressions:
                - key: kubernetes.io/hostname  # è¿™ä¸ªæ˜¯ç³»ç»Ÿè‡ªåŠ¨ç»™æ¯ä¸ªèŠ‚ç‚¹æ‰“çš„æ ‡ç­¾ï¼Œå€¼å°±æ˜¯èŠ‚ç‚¹åï¼ˆæ¯”å¦‚ node1, node2ï¼‰
                  operator: In       # è¡¨ç¤ºâ€œåœ¨è¿™äº›å€¼ä¸­â€
                  values:
                    - node2          # åªèƒ½åœ¨ node2 èŠ‚ç‚¹ä¸Šä½¿ç”¨
    
    ```
    
2. redis-pvc.yaml
    
    ```yaml
    apiVersion: v1
    kind: PersistentVolumeClaim      # å®šä¹‰çš„æ˜¯â€œç”³è¯·â€ä¸€å—å­˜å‚¨èµ„æº
    metadata:
      name: redis-pvc                # PVC çš„åå­—ï¼Œåœ¨ Deployment ä¸­å¼•ç”¨
      namespace: tiktok
    spec:
      accessModes:
        - ReadWriteOnce              # è¯·æ±‚çš„è®¿é—®æ¨¡å¼è¦ä¸ PV ä¿æŒä¸€è‡´
      resources:
        requests:
          storage: 1Gi               # è¯·æ±‚çš„å­˜å‚¨å¤§å°
      volumeName: redis-pv           # æŒ‡å®šè¦ç»‘å®šçš„ PV åç§°ï¼ˆæ‰‹åŠ¨ç»‘å®šï¼‰
    
    ```
    
3. deployment.yaml
    
    ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: redis
      namespace: tiktok
    spec:
      replicas: 1                    # åªè¿è¡Œä¸€ä¸ª Redis å®ä¾‹
      selector:
        matchLabels:
          app: redis                 # ç”¨äºåŒ¹é… Pod çš„æ ‡ç­¾
      template:
        metadata:
          labels:
            app: redis
        spec:
          nodeSelector:              # æŒ‡å®š pod è¦è°ƒåº¦åˆ° node2 èŠ‚ç‚¹
            kubernetes.io/hostname: node2
          containers:
            - name: redis
              image: redis:7.2.4     # Redis é•œåƒç‰ˆæœ¬
              ports:
                - containerPort: 6379  # Redis é»˜è®¤ç«¯å£
              volumeMounts:
                - name: redis-data   # å®šä¹‰æŒ‚è½½çš„æ•°æ®å·
                  mountPath: /data   # Redis ä¼šå°†æ•°æ®ä¿å­˜åœ¨æ­¤ç›®å½•ä¸­
          volumes:
            - name: redis-data
              persistentVolumeClaim:
                claimName: redis-pvc # æŒ‚è½½ä¸Šé¢ç”³è¯·çš„ PVC
    
    ```
    
4. service.yaml
    
    ```yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: redis
      namespace: tiktok
    spec:
      type: NodePort                 # å¯¹å¤–æš´éœ²ç«¯å£
      selector:
        app: redis                   # åŒ¹é… Pod çš„æ ‡ç­¾
      ports:
        - port: 6379                 # é›†ç¾¤å†…éƒ¨è®¿é—®ç«¯å£
          targetPort: 6379          # å®¹å™¨å†…éƒ¨ Redis çš„ç«¯å£
          nodePort: 30379           # å¤–éƒ¨é€šè¿‡è¿™ä¸ªç«¯å£è®¿é—® Redis
    
    ```
    
    | é¡¹ç›® | å«ä¹‰ |
    | --- | --- |
    | `PersistentVolume (PV)` | ç®¡ç†å‘˜æä¾›çš„**å®é™…å­˜å‚¨èµ„æº**ï¼Œå¯ä»¥æ˜¯æœ¬åœ°ç›®å½•ã€NFSã€äº‘ç£ç›˜ç­‰ |
    | `PersistentVolumeClaim (PVC)` | ç”¨æˆ·å‘é›†ç¾¤ç”³è¯·**æŸç§å¤§å°å’Œè®¿é—®æƒé™çš„å­˜å‚¨å·** |
    | **ç»‘å®šå…³ç³»** | å½“ PVC å’Œ PV çš„å±æ€§ï¼ˆå¦‚å®¹é‡ã€è®¿é—®æ¨¡å¼ï¼‰åŒ¹é…æ—¶ï¼ŒK8s ä¼šè‡ªåŠ¨æˆ–æ‰‹åŠ¨å°† PVC ç»‘å®šåˆ°æŸä¸ª PV |
    | **æŒ‚è½½åˆ° Pod** | Pod ä¸­é€šè¿‡ `volumeMounts` ä½¿ç”¨ PVCï¼Œä»è€Œé—´æ¥ä½¿ç”¨ç»‘å®šçš„ PVï¼ˆç£ç›˜ï¼‰ |
5. æŒä¹…åŒ–æ–‡ä»¶
    
    ```yaml
    // node2
    mkdir -p /data/redis
    chmod 777 /data/redis
    ```
    
6. éƒ¨ç½²
    
    ```yaml
    kubectl apply -f k8s/redis/redis-pv.yaml
    kubectl apply -f k8s/redis/redis-pvc.yaml
    kubectl apply -f k8s/redis/deployment.yaml
    kubectl apply -f k8s/redis/service.yaml
    ```
    

## 4. kafka

1. kafka
    
    ```yaml
    # pv-pvc.yaml
    apiVersion: v1
    kind: PersistentVolume
    metadata:
      name: kafka-pv
      namespace: tiktok
    spec:
      capacity:
        storage: 2Gi
      accessModes:
        - ReadWriteOnce
      persistentVolumeReclaimPolicy: Retain
      hostPath:
        path: /data/kafka
      nodeAffinity:
        required:
          nodeSelectorTerms:
            - matchExpressions:
                - key: kubernetes.io/hostname
                  operator: In
                  values:
                    - node2
    ---
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: kafka-pvc
      namespace: tiktok
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 2Gi
    
          
    # deployment.yaml
    [root@master kafka]# cat kafka-deployment.yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: kafka
      namespace: tiktok
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: kafka
      template:
        metadata:
          labels:
            app: kafka
        spec:
          nodeSelector:
            kubernetes.io/hostname: node2
          containers:
            - name: kafka
              image: bitnami/kafka:3.6.1
              imagePullPolicy: IfNotPresent
              ports:
                - containerPort: 19092
              env:
                - name: KAFKA_ENABLE_KRAFT
                  value: "yes"
                - name: KAFKA_CFG_NODE_ID
                  value: "0"
                - name: KAFKA_CFG_PROCESS_ROLES
                  value: "broker,controller"
                - name: KAFKA_CFG_CONTROLLER_LISTENER_NAMES
                  value: "CONTROLLER"
                - name: KAFKA_CFG_LISTENERS
                  value: "PLAINTEXT://:19092,CONTROLLER://:9093"
                - name: KAFKA_CFG_ADVERTISED_LISTENERS
                  value: "PLAINTEXT://kafka.tiktok.svc.cluster.local:19092"
                - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
                  value: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
                - name: KAFKA_CFG_INTER_BROKER_LISTENER_NAME
                  value: "PLAINTEXT"
                - name: KAFKA_CFG_CONTROLLER_QUORUM_VOTERS
                  value: "0@kafka:9093"
              volumeMounts:
                - name: kafka-data
                  mountPath: /bitnami/kafka
          volumes:
            - name: kafka-data
              persistentVolumeClaim:
                claimName: kafka-pvc
    
      
      # service.yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: kafka
      namespace: tiktok
    spec:
      selector:
        app: kafka
      ports:
        - name: broker
          port: 19092
          targetPort: 19092
        - name: controller
          port: 9093
          targetPort: 9093
    
    ```
    
2. kafka-ui
    
    ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: kafdrop
      namespace: tiktok
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: kafdrop
      template:
        metadata:
          labels:
            app: kafdrop
        spec:
          containers:
            - name: kafdrop
              image: obsidiandynamics/kafdrop:latest
              imagePullPolicy: IfNotPresent
              ports:
                - containerPort: 9000
              env:
                - name: KAFKA_BROKERCONNECT
                  value: "kafka:19092"  # æˆ–è€…ç”¨ä½ çš„å®é™… ClusterIP / Service åå­—å’Œç«¯å£
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: kafdrop
      namespace: tiktok
    spec:
      selector:
        app: kafdrop
      ports:
        - protocol: TCP
          port: 9000
          targetPort: 9000
      type: NodePort
    
    ```
    
3. canal
    
    ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: canal
      namespace: tiktok
      labels:
        app: canal
    spec:
      replicas: 1  # åªéƒ¨ç½²ä¸€ä¸ªå®ä¾‹
      selector:
        matchLabels:
          app: canal
      template:
        metadata:
          labels:
            app: canal
        spec:
          initContainers:
          - name: wait-for-mysql
            image: busybox:1.35
            command: ['sh', '-c', 'until nc -z mysql 3306; do echo waiting for mysql; sleep 2; done']
          - name: wait-for-kafka
            image: busybox:1.35
            command: ['sh', '-c', 'until nc -z kafka 19092; do echo waiting for kafka; sleep 2; done']
          nodeSelector:
            kubernetes.io/hostname: node2  # ä¿è¯ Pod è¢«è°ƒåº¦åˆ° node2
          containers:
            - name: canal
              image: canal/canal-server:latest
              imagePullPolicy: IfNotPresent
              ports:
                - containerPort: 11111  # é»˜è®¤ Canal Server çš„ TCP ç«¯å£
              env:
                - name: canal.instance.master.address
                  value: "mysql:3306"  # ä¸ä½  MySQL çš„ service åä¸€è‡´
                - name: canal.instance.dbUsername
                  value: "ysh"
                - name: canal.instance.dbPassword
                  value: "ysh"
                - name: canal.auto.scan
                  value: "true"
              volumeMounts:
                - name: canal-conf
                  mountPath: /home/admin/canal-server/conf
    
          volumes:
            - name: canal-conf
              hostPath:
                path: /data/canal/canal-conf  # node2 ä¸Šçš„é…ç½®ç›®å½•
                type: Directory
    
    apiVersion: v1
    kind: Service
    metadata:
      name: canal
      namespace: tiktok
    spec:
      selector:
        app: canal
      ports:
        - name: tcp
          port: 11111
          targetPort: 11111
          protocol: TCP
      type: ClusterIP  # æˆ– NodePort å¦‚æœä½ æƒ³ä»é›†ç¾¤å¤–è®¿é—®
    
    # node2 
    å°†canalé…ç½®æ–‡ä»¶ä¸Šä¼ ï¼Œåˆ é™¤meta
    
    kubectl apply -f ../zoo1/zoo1.yaml
    mkdir kafak
    chmod 777 kafka
    kubectl apply -f kafka-pv-pvc.yaml
    kubectl apply -f kafka-deployment.yaml
    kubectl apply -f kafka-service.yaml
    kubectl apply -f kafka-ui.yaml
    kubectl apply -f canal-deployment.yaml
    kubectl apply -f canal-service.yaml
    ```
    

è¦é‡æ–°é…ç½®å°±å…¨åˆ äº†

```yaml
kubectl get pod -n tiktok
kubectl describe pod -n tiktok

kubectl delete deployment zoo1 -n tiktok
kubectl delete deployment kafka -n tiktok
kubectl delete deployment kafka-ui -n tiktok
kubectl delete deployment canal -n tiktok

kubectl delete service zoo1 -n tiktok
kubectl delete service kafka -n tiktok
kubectl delete service kafka-ui -n tiktok
kubectl delete service canal -n tiktok

kubectl delete pvc kafka-pvc -n tiktok
kubectl delete pv kafka-pv

// åŠ é•œåƒ

vim /etc/docker/daemon.json
sudo systemctl daemon-reload
sudo systemctl restart docker

kubectl delete deployment elasticsearch -n tiktok
kubectl delete deployment kibana -n tiktok
kubectl delete service elasticsearch  -n tiktok
kubectl delete service kibana -n tiktok
kubectl delete pvc es-pvc -n tiktok
kubectl delete pv es-pv
```

## 5. es

1. es
    
    ```yaml
    apiVersion: v1
    kind: PersistentVolume
    metadata:
      name: es-pv
      namespace: tiktok
    spec:
      capacity:
        storage: 2Gi
      accessModes:
        - ReadWriteOnce
      persistentVolumeReclaimPolicy: Retain
      hostPath:
        path: /data/es
      nodeAffinity:
        required:
          nodeSelectorTerms:
            - matchExpressions:
                - key: kubernetes.io/hostname
                  operator: In
                  values:
                    - node2
    ---
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: es-pvc
      namespace: tiktok
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 2Gi
    
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: elasticsearch
      namespace: tiktok
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: elasticsearch
      template:
        metadata:
          labels:
            app: elasticsearch
        spec:
          nodeSelector:
            kubernetes.io/hostname: node2
          initContainers:
          - name: wait-for-kafka
            image: busybox:1.35
            command: ['sh', '-c', 'until nc -z kafka 19092; do echo waiting for kafka; sleep 2; done']
          containers:
          - name: elasticsearch
            image: docker.elastic.co/elasticsearch/elasticsearch:7.17.10
            ports:
            - containerPort: 9200
            - containerPort: 9300
            env:
            - name: discovery.type
              value: single-node
            - name: ES_JAVA_OPTS
              value: "-Xms256m -Xmx256m"
            - name: xpack.security.enabled
              value: "false"
            resources:
              requests:
                memory: "512Mi"               # è¯·æ±‚512MBå†…å­˜
                cpu: "250m"                  # è¯·æ±‚0.25ä¸ªCPU
              limits:
                memory: "768Mi"              # é™åˆ¶æœ€å¤§768MBå†…å­˜
                cpu: "500m"                  # é™åˆ¶æœ€å¤§0.5ä¸ªCPU
            volumeMounts:
              - name: es-data
                mountPath: /usr/share/elasticsearch/data
          volumes:
          - name: es-data
            persistentVolumeClaim:
              claimName: es-pvc
    
    apiVersion: v1
    kind: Service
    metadata:
      name: elasticsearch
      namespace: tiktok
    spec:
      selector:
        app: elasticsearch
      ports:
        - name: http
          port: 9200
          targetPort: 9200
        - name: transport
          port: 9300
          targetPort: 9300
      type: ClusterIP
    
    ```
    
2. ui
    
    ```yaml
    kind: Deployment
    metadata:
      name: kibana
      namespace: tiktok
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: kibana
      template:
        metadata:
          labels:
            app: kibana
        spec:
          containers:
            - name: kibana
              image: docker.elastic.co/kibana/kibana:7.17.10
              ports:
                - containerPort: 5601
              env:
                - name: ELASTICSEARCH_HOSTS
                  value: "http://elasticsearch.tiktok.svc.cluster.local:9200"
                - name: XPACK_SECURITY_ENABLED
                  value: "false"
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: kibana
      namespace: tiktok
    spec:
      selector:
        app: kibana
      ports:
        - port: 5601
          targetPort: 5601
      type: NodePort
    ```
    

# è™šæ‹Ÿæœº

1. è™šæ‹Ÿæœºè¿æ¥ä¸ä¸Šçš„é—®é¢˜
    
    ```yaml
    https://cloud.tencent.com/developer/article/2110372
    ```
    
2. k8séƒ¨ç½²æ¡†æ¶é—®é¢˜
    
    ```yaml
    uname -m
    x86_64
    
    åœ¨ç¼–è¯‘çš„æ—¶å€™è¦è½¬ä¸ºamdçš„ // dockerfile
    RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o bin/job-service ./cmd/job-service
    ```